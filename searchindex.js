Search.setIndex({"docnames": ["about/authors", "about/changelog", "about/index", "api/_autosummary/lmflow.args", "autoapi/index", "autoapi/lmflow/args/index", "autoapi/lmflow/datasets/dataset/index", "autoapi/lmflow/datasets/index", "autoapi/lmflow/datasets/multi_modal_dataset/index", "autoapi/lmflow/index", "autoapi/lmflow/models/auto_model/index", "autoapi/lmflow/models/base_model/index", "autoapi/lmflow/models/decoder_model/index", "autoapi/lmflow/models/encoder_decoder_model/index", "autoapi/lmflow/models/hf_decoder_model/index", "autoapi/lmflow/models/hf_encoder_decoder_model/index", "autoapi/lmflow/models/index", "autoapi/lmflow/models/interfaces/index", "autoapi/lmflow/models/interfaces/tunable/index", "autoapi/lmflow/models/regression_model/index", "autoapi/lmflow/models/text_regression_model/index", "autoapi/lmflow/models/vision2seq_model/index", "autoapi/lmflow/models/vision_encoder/clip_encoder/index", "autoapi/lmflow/models/vision_encoder/index", "autoapi/lmflow/pipeline/auto_pipeline/index", "autoapi/lmflow/pipeline/base_aligner/index", "autoapi/lmflow/pipeline/base_pipeline/index", "autoapi/lmflow/pipeline/base_tuner/index", "autoapi/lmflow/pipeline/evaluator/index", "autoapi/lmflow/pipeline/finetuner/index", "autoapi/lmflow/pipeline/index", "autoapi/lmflow/pipeline/inferencer/index", "autoapi/lmflow/pipeline/raft_aligner/index", "autoapi/lmflow/pipeline/utils/index", "autoapi/lmflow/pipeline/utils/peft_trainer/index", "autoapi/lmflow/pipeline/utils/raft_trainer/index", "autoapi/lmflow/utils/constants/index", "autoapi/lmflow/utils/data_utils/index", "autoapi/lmflow/utils/flash_attention/bloom_flash_attention/index", "autoapi/lmflow/utils/flash_attention/gpt2_flash_attention/index", "autoapi/lmflow/utils/flash_attention/gpt_neo_flash_attention/index", "autoapi/lmflow/utils/flash_attention/index", "autoapi/lmflow/utils/flash_attention/llama_flash_attention/index", "autoapi/lmflow/utils/flash_attention/triton_flash_attention/index", "autoapi/lmflow/utils/index", "autoapi/lmflow/utils/llava_conversation_lib/index", "autoapi/lmflow/utils/multimodal/index", "autoapi/lmflow/utils/position_interpolation/index", "autoapi/lmflow/utils/position_interpolation/llama_rope_scaled_monkey_patch/index", "autoapi/lmflow/version/index", "blogs/benchmark", "blogs/index", "examples/DATASETS", "examples/TASK_GUIDE", "examples/checkpoints", "examples/index", "examples/medical_finetune", "examples/raft", "examples/reward_modeling", "index"], "filenames": ["about/authors.md", "about/changelog.md", "about/index.md", "api/_autosummary/lmflow.args.rst", "autoapi/index.rst", "autoapi/lmflow/args/index.rst", "autoapi/lmflow/datasets/dataset/index.rst", "autoapi/lmflow/datasets/index.rst", "autoapi/lmflow/datasets/multi_modal_dataset/index.rst", "autoapi/lmflow/index.rst", "autoapi/lmflow/models/auto_model/index.rst", "autoapi/lmflow/models/base_model/index.rst", "autoapi/lmflow/models/decoder_model/index.rst", "autoapi/lmflow/models/encoder_decoder_model/index.rst", "autoapi/lmflow/models/hf_decoder_model/index.rst", "autoapi/lmflow/models/hf_encoder_decoder_model/index.rst", "autoapi/lmflow/models/index.rst", "autoapi/lmflow/models/interfaces/index.rst", "autoapi/lmflow/models/interfaces/tunable/index.rst", "autoapi/lmflow/models/regression_model/index.rst", "autoapi/lmflow/models/text_regression_model/index.rst", "autoapi/lmflow/models/vision2seq_model/index.rst", "autoapi/lmflow/models/vision_encoder/clip_encoder/index.rst", "autoapi/lmflow/models/vision_encoder/index.rst", "autoapi/lmflow/pipeline/auto_pipeline/index.rst", "autoapi/lmflow/pipeline/base_aligner/index.rst", "autoapi/lmflow/pipeline/base_pipeline/index.rst", "autoapi/lmflow/pipeline/base_tuner/index.rst", "autoapi/lmflow/pipeline/evaluator/index.rst", "autoapi/lmflow/pipeline/finetuner/index.rst", "autoapi/lmflow/pipeline/index.rst", "autoapi/lmflow/pipeline/inferencer/index.rst", "autoapi/lmflow/pipeline/raft_aligner/index.rst", "autoapi/lmflow/pipeline/utils/index.rst", "autoapi/lmflow/pipeline/utils/peft_trainer/index.rst", "autoapi/lmflow/pipeline/utils/raft_trainer/index.rst", "autoapi/lmflow/utils/constants/index.rst", "autoapi/lmflow/utils/data_utils/index.rst", "autoapi/lmflow/utils/flash_attention/bloom_flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/gpt2_flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/gpt_neo_flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/llama_flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/triton_flash_attention/index.rst", "autoapi/lmflow/utils/index.rst", "autoapi/lmflow/utils/llava_conversation_lib/index.rst", "autoapi/lmflow/utils/multimodal/index.rst", "autoapi/lmflow/utils/position_interpolation/index.rst", "autoapi/lmflow/utils/position_interpolation/llama_rope_scaled_monkey_patch/index.rst", "autoapi/lmflow/version/index.rst", "blogs/benchmark.md", "blogs/index.md", "examples/DATASETS.md", "examples/TASK_GUIDE.md", "examples/checkpoints.md", "examples/index.md", "examples/medical_finetune.md", "examples/raft.md", "examples/reward_modeling.md", "index.md"], "titles": ["Contributors", "Changelog", "About", "lmflow.args", "API Reference", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.args</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.datasets.dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.datasets</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.datasets.multi_modal_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.auto_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.base_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.encoder_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.hf_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.hf_encoder_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.interfaces</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.interfaces.tunable</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.regression_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.text_regression_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.vision2seq_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.vision_encoder.clip_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.vision_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.auto_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_aligner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_tuner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.evaluator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.finetuner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.inferencer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.raft_aligner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.utils.peft_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.utils.raft_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.constants</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.data_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention.bloom_flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention.gpt2_flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention.gpt_neo_flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention.llama_flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention.triton_flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.llava_conversation_lib</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.multimodal</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.position_interpolation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.version</span></code>", "LMFlow Benchmark: An Automatic Evaluation Framework for Open-Source LLMs", "Blogs", "Dataset", "LMFlow Benchmark Guide", "Checkpoints", "Examples", "Finetune", "RAFT", "Reward Modeling", "LMFlow"], "terms": {"shizh": [0, 59], "diao": [0, 59], "rui": [0, 59], "pan": [0, 59], "hanz": [0, 59], "dong": [0, 59], "ka": 0, "shun": 0, "shum": [0, 59], "jipeng": [0, 59], "zhang": [0, 59], "wei": [0, 59], "xiong": [0, 59], "tong": [0, 59], "The": [1, 5, 6, 7, 8, 12, 13, 14, 15, 21, 24, 28, 29, 31, 32, 34, 35, 37, 43, 50, 52, 57, 58, 59], "first": [1, 35, 43, 50, 53, 54, 57, 58], "public": [1, 57], "task": [1, 14, 15, 35, 50, 55, 57], "tune": [1, 8, 14, 15, 27, 29, 34, 35, 50, 56, 57, 58], "instruct": [1, 58], "user": [1, 50, 52, 53, 57, 59], "defin": [1, 3, 5, 6, 7, 8, 34, 35, 43, 52], "dataset": [1, 3, 4, 5, 9, 14, 15, 20, 25, 27, 28, 29, 31, 32, 34, 35, 37, 50, 55, 56, 58, 59], "A": [1, 6, 7, 12, 13, 14, 15, 20, 21, 25, 27, 28, 32, 34, 35, 37, 45, 50, 57, 58], "simpl": [1, 21, 34, 35, 50, 57, 58, 59], "extens": [1, 57, 59], "api": [1, 50, 59], "develop": [1, 50, 57], "effici": [1, 50, 57, 59], "finetun": [1, 4, 9, 30, 50, 52, 54, 59], "lora": [1, 14, 15, 55, 58, 59], "simplifi": [1, 28, 29, 31, 32, 58, 59], "model": [1, 3, 4, 5, 8, 9, 25, 27, 28, 29, 31, 32, 34, 35, 46, 48, 50, 52, 54, 55, 56, 59], "infer": [1, 5, 14, 15, 20, 21, 28, 31, 52, 57, 59], "framework": [1, 51, 57, 58], "changelog": [2, 59], "version": [2, 3, 4, 5, 9, 43, 45, 50], "0": [2, 9, 14, 21, 28, 31, 32, 35, 43, 49, 50, 54, 57, 58, 59], "1": [2, 4, 5, 6, 7, 14, 21, 22, 28, 31, 35, 43, 48, 50, 52, 55, 56, 59], "mar": 2, "28": [2, 59], "2023": [2, 50, 59], "contributor": [2, 59], "thi": [3, 4, 5, 6, 7, 8, 12, 13, 14, 15, 22, 32, 34, 35, 37, 43, 48, 50, 52, 53, 57, 58, 59], "script": [3, 5, 35, 54, 56, 57, 58], "dataclass": [3, 5], "modelargu": [3, 5, 28, 29, 31, 32, 56], "datasetargu": [3, 5, 6, 7, 8, 28, 29, 31, 32, 56], "contain": [3, 4, 5, 6, 7, 12, 13, 21, 22, 28, 29, 31, 32, 34, 35, 48, 50, 52, 57], "argument": [3, 5, 6, 7, 14, 15, 20, 28, 29, 31, 32, 34, 35, 37, 43, 56], "us": [3, 5, 11, 12, 13, 14, 15, 18, 19, 21, 26, 28, 31, 34, 35, 36, 37, 43, 50, 52, 53, 54, 55, 57, 58, 59], "train": [3, 5, 14, 15, 22, 29, 32, 34, 35, 37, 48, 50, 52, 53, 57, 58, 59], "It": [3, 5, 14, 15, 28, 35, 43, 50, 57, 58, 59], "import": [3, 5, 21, 22, 28, 34, 35, 48, 50, 56, 57, 59], "sever": [3, 5, 14, 15, 35, 37, 50, 52, 53, 55], "modul": 3, "includ": [3, 5, 6, 7, 35, 37, 50, 57, 58, 59], "field": [3, 5, 57, 58, 59], "from": [3, 5, 6, 7, 14, 15, 21, 22, 28, 31, 34, 35, 37, 43, 50, 54, 56, 57, 58, 59], "type": [3, 5, 6, 7, 10, 20, 35, 50, 52, 53, 57, 58, 59], "option": [3, 5, 6, 7, 12, 13, 14, 15, 20, 21, 29, 31, 32, 34, 35, 38, 39, 42, 43, 50, 54, 57], "require_vers": [3, 5], "transform": [3, 5, 8, 14, 15, 21, 34, 35, 56], "util": [3, 4, 5, 7, 8, 9, 30, 32, 50, 58, 59], "model_for_causal_lm_map": [3, 5], "trainingargu": [3, 5, 34, 35], "model_config_class": [3, 5], "i": [3, 5, 7, 8, 14, 15, 21, 22, 25, 27, 28, 31, 32, 34, 35, 43, 48, 50, 52, 54, 57, 58, 59], "assign": [3, 5, 22, 48, 57], "list": [3, 5, 6, 7, 14, 15, 21, 34, 35, 37, 45, 52, 57, 59], "config": [3, 5, 21, 22, 46, 56, 58], "class": 3, "model_typ": [3, 5], "tupl": [3, 5, 21, 34, 35, 38, 39, 42, 43], "extract": [3, 5, 37, 57], "page": [4, 50, 59], "auto": [4, 5], "gener": [4, 5, 8, 14, 15, 19, 21, 28, 31, 32, 34, 35, 37, 43, 50, 54, 55, 57, 58, 59], "document": [4, 35, 50], "lmflow": [4, 51, 55, 56, 57, 58], "multi_modal_dataset": [4, 7, 9], "interfac": [4, 9, 14, 15, 16, 21], "tunabl": [4, 9, 14, 15, 16, 17, 27], "vision_encod": [4, 9, 16], "clip_encod": [4, 9, 16, 23], "auto_model": [4, 9, 16], "base_model": [4, 9, 12, 13, 16, 19, 21], "decoder_model": [4, 9, 14, 16], "encoder_decoder_model": [4, 9, 15, 16], "hf_decoder_model": [4, 9, 16, 31], "hf_encoder_decoder_model": [4, 9, 16], "regression_model": [4, 9, 16, 20], "text_regression_model": [4, 9, 16], "vision2seq_model": [4, 9, 16], "pipelin": [4, 9, 52, 56, 57, 59], "peft_train": [4, 9, 30, 33], "raft_train": [4, 9, 30, 33], "auto_pipelin": [4, 9, 30, 56], "base_align": [4, 9, 30, 32], "base_pipelin": [4, 9, 25, 27, 28, 30, 31], "base_tun": [4, 9, 29, 30], "evalu": [4, 5, 9, 22, 30, 34, 35, 48, 51, 52, 54, 57, 58, 59], "inferenc": [4, 5, 9, 30, 52], "raft_align": [4, 9, 30, 57], "flash_attent": [4, 9, 44], "bloom_flash_attent": [4, 9, 41, 44], "gpt2_flash_attent": [4, 9, 41, 44], "gpt_neo_flash_attent": [4, 9, 41, 44], "llama_flash_attent": [4, 9, 41, 44], "triton_flash_attent": [4, 9, 41, 44], "position_interpol": [4, 9, 44], "llama_rope_scaled_monkey_patch": [4, 9, 44, 47], "constant": [4, 9, 44], "data_util": [4, 9, 44], "llava_conversation_lib": [4, 9, 44], "multimod": [4, 9, 44], "arg": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 24, 25, 27, 29, 31, 32, 34, 35, 37, 43, 45, 56], "creat": [4, 6, 7, 11, 12, 13, 18, 19, 26, 28, 34, 35, 43, 55, 57, 58, 59], "sphinx": 4, "autoapi": 4, "sourc": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 48, 49, 51, 52, 57, 59], "decor": 5, "paramet": [5, 6, 7, 14, 15, 20, 22, 28, 29, 31, 32, 34, 35, 37, 48, 55, 58, 59], "can": [5, 14, 15, 22, 34, 35, 43, 48, 50, 52, 53, 54, 57, 58, 59], "configur": [5, 57], "model_name_or_path": [5, 53, 54, 57, 58], "str": [5, 6, 7, 8, 14, 15, 31, 34, 35, 37, 45, 57], "string": [5, 6, 7, 14, 15, 21, 31, 34, 35, 37], "repres": [5, 6, 7, 14, 15, 22, 28, 43, 48], "path": [5, 14, 15, 20, 21, 35, 53, 54, 56, 57], "name": [5, 14, 15, 20, 24, 34, 35, 37, 43, 50, 52, 53, 57], "pretrain": [5, 14, 15, 21, 35, 50, 54, 59], "checkpoint": [5, 34, 35, 50, 55, 57], "weight": [5, 21, 28, 59], "initi": [5, 6, 7, 14, 15, 20, 21, 28, 29, 31, 32, 35, 56, 57, 58], "If": [5, 34, 35, 37, 43, 50, 53, 56, 57, 58, 59], "none": [5, 6, 7, 8, 14, 15, 21, 22, 28, 29, 32, 34, 35, 37, 38, 39, 40, 42, 43, 48, 58], "scratch": 5, "provid": [5, 11, 12, 13, 14, 15, 18, 19, 21, 26, 28, 31, 34, 35, 50, 52, 53, 55, 57, 58, 59], "config_overrid": 5, "default": [5, 6, 7, 14, 15, 31, 34, 35, 37, 57], "set": [5, 14, 15, 34, 35, 37, 50, 52, 54, 55, 57, 58], "overrid": [5, 21, 35], "when": [5, 22, 31, 34, 35, 48, 50, 57, 58], "config_nam": 5, "differ": [5, 6, 7, 14, 15, 34, 35, 43, 45, 50, 54, 57, 58], "tokenizer_nam": 5, "token": [5, 7, 8, 14, 15, 21, 28, 31, 32, 34, 35, 50, 56, 57, 58], "cache_dir": 5, "directori": [5, 14, 15, 28, 34, 35, 52, 57], "where": [5, 28, 50, 52, 57, 58, 59], "download": [5, 21, 50, 52, 53, 54, 57], "huggingfac": [5, 6, 7, 14, 15, 54, 57, 58], "co": [5, 57], "store": [5, 43, 57], "use_fast_token": 5, "bool": [5, 8, 21, 22, 31, 35, 37, 38, 39, 42, 45, 48], "boolean": [5, 22, 43, 48], "indic": [5, 21, 50, 52], "whether": [5, 8, 14, 15, 22, 34, 35, 43, 48, 57, 59], "fast": 5, "back": [5, 57, 58], "librari": [5, 34, 35], "model_revis": 5, "specif": [5, 50, 52, 57, 58, 59], "branch": [5, 53], "tag": [5, 35], "commit": [5, 35], "id": [5, 14, 15, 21], "use_auth_token": 5, "run": [5, 28, 29, 32, 34, 35, 50, 52, 53, 54, 57, 58], "cli": 5, "login": 5, "necessari": [5, 35, 50], "privat": 5, "torch_dtyp": [5, 21], "dtype": [5, 22, 35], "load": [5, 6, 7, 14, 15, 21, 28, 29, 31, 32, 35, 37, 54], "under": [5, 34, 35, 50, 52, 53, 59], "pass": [5, 34, 35, 43, 50, 56, 59], "automat": [5, 10, 24, 34, 35, 43, 51, 57], "deriv": 5, "": [5, 34, 35, 50, 53, 56, 57, 58, 59], "use_ram_optimized_load": [5, 53], "disk": 5, "map": [5, 6, 7, 20, 56, 58], "memori": [5, 57], "enough": 5, "use_int8": 5, "int8": 5, "quantiz": 5, "lora_model_path": [5, 54], "arch_typ": 5, "trust_remote_cod": 5, "use_lora": 5, "use_qlora": 5, "bit": [5, 43, 57, 58], "int": [5, 14, 15, 31, 35, 37, 38, 45, 57, 58], "quant_typ": 5, "double_qu": 5, "lora_r": 5, "lora_alpha": 5, "lora_target_modul": 5, "lora_dropout": 5, "float": [5, 20, 28, 31, 35, 57], "save_aggregated_lora": 5, "use_flash_attent": 5, "truncate_to_model_max_length": 5, "do_rope_sc": 5, "rope_pi_ratio": 5, "rope_ntk_ratio": 5, "__post_init__": 5, "vismodelargu": 5, "base": [5, 7, 8, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 43, 45, 48, 50, 57, 58, 59], "low_resourc": [5, 21], "custom_model": [5, 15], "pretrained_language_projection_path": 5, "custom_vision_model": 5, "image_encoder_name_or_path": [5, 21], "qformer_name_or_path": [5, 21], "llm_model_name_or_path": 5, "use_prompt_cach": [5, 21], "prompt_cache_path": 5, "llava_load": 5, "with_qform": 5, "vision_select_lay": 5, "llava_pretrain_model_path": 5, "save_pretrain_model_path": 5, "languag": [5, 14, 15, 28, 29, 35, 43, 50, 59], "dataset_path": [5, 7, 8, 54, 57, 58], "dataset_nam": [5, 53], "valu": [5, 31, 34, 35, 40, 43, 53, 57], "custom": [5, 34, 35, 43, 52, 57, 58], "is_custom_dataset": 5, "data": [5, 6, 7, 8, 20, 28, 29, 32, 34, 35, 37, 50, 52, 53, 54, 57, 58, 59], "fals": [5, 8, 14, 15, 21, 22, 31, 34, 35, 38, 39, 40, 42, 43, 45, 53, 57, 58], "customized_cache_dir": 5, "cach": [5, 6, 7, 34, 35], "dataset_config_nam": 5, "via": [5, 50, 57], "train_fil": 5, "input": [5, 8, 14, 15, 20, 21, 28, 31, 32, 34, 35, 37, 42, 43, 50, 52, 53, 54, 58], "file": [5, 28, 35, 37, 52, 55, 56, 57, 59], "text": [5, 8, 14, 15, 21, 28, 29, 31, 32, 37, 50, 52, 54, 56, 57, 58, 59], "validation_fil": 5, "perplex": [5, 50], "max_train_sampl": 5, "an": [5, 11, 12, 13, 18, 19, 21, 22, 26, 34, 35, 43, 48, 51, 57, 58, 59], "integ": 5, "maximum": [5, 28, 29, 31, 34, 35], "number": [5, 28, 31, 35, 57, 58], "exampl": [5, 8, 12, 13, 21, 22, 34, 35, 37, 43, 48, 50, 52, 53, 54, 59], "debug": 5, "quicker": 5, "truncat": [5, 58], "max_eval_sampl": 5, "stream": [5, 21], "enabl": [5, 59], "mode": [5, 22, 34, 35, 43, 48, 57], "block_siz": 5, "sequenc": [5, 14, 15, 21, 35, 43, 50], "length": [5, 14, 15, 21, 28, 29, 31, 34, 35, 37, 43, 50], "after": [5, 8, 31, 34, 50, 53, 57], "block": [5, 29, 35], "size": [5, 21, 28, 34, 35, 43, 50, 57, 58], "also": [5, 12, 13, 22, 28, 35, 43, 48, 50, 53, 57, 58, 59], "some": [5, 28, 34, 35, 50, 53, 57, 58, 59], "addit": [5, 8, 35], "further": [5, 50, 57, 59], "overwrite_cach": 5, "validation_split_percentag": [5, 57, 58], "preprocessing_num_work": 5, "disable_group_text": 5, "demo_example_in_prompt": 5, "explanation_in_prompt": 5, "keep_linebreak": 5, "prompt_structur": [5, 31, 53, 54], "function": [5, 12, 13, 20, 21, 32, 34, 35, 57, 58, 59], "help": [5, 50, 57, 58, 59], "messag": [5, 6, 7, 35, 45], "each": [5, 31, 34, 35, 43, 52, 57, 58], "hint": [5, 6, 7], "metadata": [5, 35, 57], "inform": [5, 6, 7, 28, 35, 57, 58, 59], "about": [5, 35, 50, 57, 58, 59], "group_texts_batch_s": 5, "test_fil": 5, "multimodaldatasetargu": 5, "image_fold": 5, "image_aspect_ratio": 5, "is_multimod": 5, "use_image_start_end": 5, "sep_styl": [5, 45], "finetunerargu": [5, 29], "adapt": [5, 14, 15, 34, 35, 57, 59], "eval_dataset_path": 5, "remove_unused_column": 5, "finetune_part": 5, "save_language_project": 5, "evaluatorargu": [5, 28], "local_rank": [5, 32], "For": [5, 34, 35, 43, 50, 52, 55, 57, 58, 59], "distribut": [5, 31, 34, 35], "random_shuffl": [5, 37], "use_wandb": [5, 28], "random_se": 5, "output_dir": [5, 34, 35, 54, 57], "mixed_precis": 5, "choic": [5, 37, 50, 57, 58], "bf16": 5, "fp16": 5, "mix": [5, 57], "precis": 5, "deepspe": [5, 14, 15, 34, 35, 53, 54, 56], "json": [5, 6, 7, 35, 37, 52, 53, 54, 56, 57, 58], "e": [5, 31, 32, 34, 35, 37, 43, 52, 53, 57, 59], "g": [5, 34, 35, 43, 52, 57], "ds_config": [5, 14, 15, 53, 54], "alreadi": [5, 35, 50, 57, 58], "dict": [5, 6, 7, 31, 34, 35, 45], "temperatur": [5, 31, 57], "control": [5, 6, 7, 31, 34, 35], "divers": [5, 50, 57], "repetition_penalti": 5, "penal": 5, "repetit": 5, "answer_typ": [5, 28, 37, 53, 54], "evaluate_block_s": 5, "metric": [5, 28, 34, 35, 53, 57], "inference_batch_size_per_devic": [5, 57], "use_accelerator_for_evalu": 5, "max_new_token": [5, 31], "inferencerargu": [5, 31], "devic": [5, 14, 15, 21, 22, 34, 35, 48, 57], "do_sampl": 5, "raftalignerargu": [5, 32], "raft": [5, 55], "align": [5, 25, 32, 55], "output_reward_path": [5, 32], "output_min_length": [5, 32], "output_max_length": [5, 32], "num_raft_iter": [5, 57], "raft_batch_s": [5, 57], "top_reward_percentag": [5, 57], "collection_strategi": [5, 57], "benchmarkingargu": 5, "lm_evaluation_metr": 5, "pipeline_argument_map": 5, "autoargu": [5, 56], "choos": [5, 34, 35, 50, 57, 58], "get_pipeline_args_class": [5, 56], "python": [6, 7, 8, 21, 50, 53, 54, 59], "code": [6, 7, 8, 22, 35, 50, 59], "method": [6, 7, 14, 15, 28, 34, 35, 43, 50, 57, 59], "manipul": [6, 7], "backend": [6, 7, 14, 15, 35, 43], "hug": [6, 7, 52], "face": [6, 7], "dictionari": [6, 7, 28, 29, 34, 35], "retriev": [6, 7, 43], "dataset_typ": 6, "text_onli": [6, 20, 31, 52, 53, 57, 58], "text2text": [6, 53, 55], "float_onli": 6, "image_text": [6, 31], "key_typ": 6, "key_inst": 6, "instanc": [6, 7, 8, 14, 15, 20, 28, 29, 34, 35, 50, 52, 57, 58, 59], "data_arg": [6, 7, 8, 24, 28, 29, 31, 32, 56], "kwarg": [6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 22, 23, 24, 25, 27, 29, 32, 34, 35, 43], "object": [6, 7, 8, 20, 28, 29, 31, 32, 34, 35], "given": [6, 7, 20, 28, 29, 31, 32, 34, 35, 43, 50, 53, 57, 58], "requir": [6, 7, 28, 29, 31, 32, 43, 50, 57, 58, 59], "posit": [6, 7, 14, 15, 20, 29, 32, 50, 57, 58, 59], "keyword": [6, 7, 14, 15, 20, 29, 32, 35], "__len__": [6, 7, 8, 35], "_check_data_format": [6, 7], "check": [6, 7, 35, 50], "structur": [6, 7, 22, 48, 57, 58], "match": [6, 7, 50], "rais": [6, 7, 35], "from_dict": [6, 7], "dict_obj": [6, 7], "return": [6, 7, 8, 14, 15, 21, 22, 24, 28, 29, 31, 32, 34, 35, 37, 43, 48, 50, 57, 58], "format": [6, 7, 31, 55], "key_1": [6, 7, 52], "value_1": [6, 7, 52], "key_2": [6, 7, 52], "2": [6, 7, 21, 31, 32, 43, 50, 52, 55, 56, 59], "value_2": [6, 7, 52], "self": [6, 7, 22, 34, 35, 38, 39, 40, 42, 43, 48, 57], "classmethod": [6, 7, 10, 24], "create_from_dict": [6, 7], "to_dict": [6, 7], "to_list": [6, 7], "get_backend": [6, 7], "get_backend_dataset": [6, 7], "backend_dataset": [6, 7], "get_fingerprint": [6, 7], "fingerprint": [6, 7], "which": [6, 7, 14, 15, 25, 27, 28, 35, 50, 52, 57, 58, 59], "get_data_arg": [6, 7], "get_typ": [6, 7], "custommultimodaldataset": [7, 8], "torch": [7, 8, 21, 22, 31, 32, 34, 35, 37, 38, 39, 42, 43, 48], "multi": [7, 8, 50], "modal": [7, 8], "register_token": [7, 8], "image_processor": [7, 8], "__getitem__": [7, 8], "preprocess_multimodal_llava": 8, "tokenizer_image_token": 8, "prompt": [8, 14, 15, 21, 31, 32, 52, 57, 58, 59], "image_token_index": [8, 21, 36], "return_tensor": [8, 21], "preprocess_llama_from_llava_plain": 8, "pretrainedtoken": 8, "has_imag": 8, "just": [8, 43, 50, 57, 58, 59], "add": [8, 34, 35, 53, 57], "imag": [8, 21, 22, 36], "front": 8, "And": 8, "don": [8, 34, 57, 58], "t": [8, 34, 35, 43, 50, 57, 58], "ani": [8, 14, 35, 50, 57, 58, 59], "process": [8, 14, 15, 21, 28, 29, 31, 32, 34, 35, 50, 55, 56, 57, 58, 59], "ha": [8, 14, 15, 28, 34, 35, 43, 50, 52], "input_id": [8, 14, 21, 22, 31, 58], "label": [8, 21, 22, 34, 35, 50, 57, 58], "preprocess_llama_from_llava_v1": 8, "put": [8, 53], "so": [8, 35, 50, 57, 58, 59], "need": [8, 34, 35, 43, 50, 53, 54, 57, 58, 59], "target": [8, 31, 35, 59], "datacollatorforsuperviseddataset": 8, "collat": [8, 35], "supervis": [8, 55], "fine": [8, 14, 15, 34, 35, 57, 58, 59], "__call__": 8, "internal_vers": 9, "4": [9, 49, 50, 52, 57, 59], "__version__": [9, 49], "get": [10, 20, 21, 32, 35, 50, 53, 54, 55, 56, 58], "correct": [10, 43, 57], "automodel": 10, "get_model": 10, "model_arg": [10, 14, 15, 20, 24, 28, 29, 31, 32, 46, 56], "basemodel": [11, 12, 13, 19, 21, 32], "abc": [11, 12, 13, 18, 19, 26], "helper": [11, 12, 13, 18, 19, 26, 35], "standard": [11, 12, 13, 18, 19, 26], "wai": [11, 12, 13, 18, 19, 22, 26, 34, 35, 48, 50, 52, 53, 54, 57, 58], "inherit": [11, 12, 13, 18, 19, 26, 35], "one": [12, 13, 34, 35, 50, 53, 56, 57, 58], "line": [12, 13, 50], "summari": [12, 13, 35], "program": [12, 13, 37, 57], "termin": [12, 13], "period": [12, 13, 50], "leav": [12, 13, 50, 57], "blank": [12, 13], "rest": [12, 13], "docstr": [12, 13], "should": [12, 13, 22, 34, 35, 43, 48, 50, 57, 58], "overal": [12, 13, 14, 15, 43, 59], "descript": [12, 13, 35, 55], "mai": [12, 13, 34, 35, 50, 52, 53, 57, 58], "brief": [12, 13], "export": [12, 13], "usag": [12, 13, 50], "typic": [12, 13, 50, 57, 58], "foo": [12, 13], "classfoo": [12, 13], "bar": [12, 13], "functionbar": [12, 13], "decodermodel": [12, 14], "encoderdecodermodel": [13, 15], "call": [14, 15, 22, 34, 35, 43, 48, 50, 57], "hfdecodermodel": [14, 15, 28, 31], "wrapper": [14, 15, 35], "around": [14, 15, 50], "__init__": [14, 15, 22, 48], "ar": [14, 15, 21, 34, 35, 43, 50, 52, 53, 54, 57, 58, 59], "take": [14, 15, 28, 32, 34, 35, 57], "tune_strategi": [14, 15], "attent": [14, 15, 21, 43], "mask": [14, 15, 21, 43], "fed": [14, 15, 35], "support": [14, 15, 31, 43, 53, 54, 55], "normal": [14, 15, 28, 50], "allow": [14, 15, 22, 35, 48, 50, 59], "howev": [14, 15, 50, 54, 57, 59], "strategi": [14, 15, 57], "yet": [14, 15, 43], "implement": [14, 15, 35, 43, 50, 53, 57], "conveni": [14, 15, 50, 57, 59], "variou": [14, 15, 35, 52, 59], "nlp": [14, 15, 50], "classif": [14, 15, 35], "question": [14, 15, 21, 32, 50, 52, 59], "answer": [14, 15, 21, 37, 50, 52, 53, 57, 58, 59], "logger": [14, 15, 29, 31, 32, 35], "models_support_flash_attent": 14, "llamaforcausallm": 14, "gptneoforcausallm": 14, "gpt2forcausallm": 14, "bloomforcausallm": 14, "gpu_support_flash_attent": 14, "gpu": [14, 15, 34, 35, 57], "use_acceler": [14, 15], "revis": [14, 15, 20], "etc": [14, 15, 20, 22, 34, 35, 48, 50, 57, 59], "configu": [14, 15], "add_special_token": 14, "true": [14, 15, 21, 28, 29, 35, 37, 43, 57, 58], "full": [14, 15, 34, 50, 57, 58, 59], "tokenized_dataset": [14, 15, 29, 56], "without": [14, 21, 35, 50, 57, 58], "lead": [14, 50, 57], "trail": 14, "special": [14, 57, 59], "thei": [14, 34, 35, 50, 52, 57, 58], "begin": [14, 57], "Of": 14, "sentenc": [14, 50], "end": [14, 35], "encod": [14, 15, 28, 52], "union": [14, 15, 21, 34, 35, 39], "perform": [14, 15, 21, 28, 29, 31, 32, 35, 43, 57, 58, 59], "output": [14, 15, 28, 31, 32, 35, 37, 43, 50, 52], "hello": [14, 59], "world": [14, 50, 57], "101": [14, 50], "7592": 14, "1010": 14, "2088": 14, "102": 14, "batch": [14, 21, 28, 34, 35, 37, 42, 43, 57, 58], "attention_mask": [14, 21, 22, 38, 39, 40, 42, 58], "token_type_id": 14, "tensor": [14, 21, 31, 34, 35, 38, 39, 42, 43], "decod": [14, 15, 28, 37, 52], "singl": [14, 34, 35, 45, 50, 52, 57, 58], "merge_lora_weight": [14, 15], "get_peft_without_qlora": 14, "save": [14, 15, 21, 34, 35, 43, 54, 57, 59], "dir": [14, 15, 53], "save_full_model": [14, 15], "get_max_length": [14, 15, 56], "max": [14, 15, 28], "accept": [14, 15, 20, 28, 34, 35, 43, 52, 57], "term": [14, 15, 50, 57], "get_token": [14, 15, 21], "get_backend_model": [14, 15, 21], "hfencoderdecodermodel": 15, "with_deepspe": 15, "pipeline_arg": [15, 24, 56], "abstract": [15, 21, 25, 27, 31], "regress": [19, 20], "regressionmodel": [19, 20, 32], "textregressionmodel": 20, "register_inference_funct": 20, "inference_func": 20, "regist": [20, 22, 43, 48], "result": [20, 43, 50, 57, 58, 59], "onli": [20, 35, 43, 50, 52, 53, 56, 57, 58, 59], "customautovision2seqmodel": 21, "blip2config": 21, "language_model_name_or_path": 21, "blip2forconditionalgener": 21, "handl": [21, 35, 57], "vision_model_from_pretrain": 21, "pretrained_path": 21, "qformer_from_pretrain": 21, "language_model_from_pretrain": 21, "vision_feature_select": 21, "image_forward_out": [21, 22], "register_prompt_cach": 21, "prompt_id": 21, "prompt_keys_valu": 21, "udpat": 21, "embed": 21, "reus": [21, 34, 35], "futur": [21, 57], "longtensor": 21, "floattensor": [21, 39], "save_prompt_cach": 21, "load_prompt_cach": 21, "forward": [21, 22, 34, 35, 38, 39, 40, 42, 43, 48], "pixel_valu": 21, "past_key_valu": [21, 22, 42], "inputs_emb": [21, 39, 42], "use_cach": [21, 38, 39, 40, 42], "output_attent": [21, 38, 39, 40, 42], "output_hidden_st": 21, "return_dict": 21, "one_sample_multiple_imag": 21, "modeling_output": 21, "causallmoutputwithpast": 21, "caption": 21, "pil": 21, "request": 21, "blip2processor": 21, "cuda": [21, 37, 43], "is_avail": 21, "els": [21, 35, 56, 57, 58], "cpu": 21, "processor": 21, "from_pretrain": [21, 35], "salesforc": 21, "blip2": 21, "opt": [21, 50, 59], "7b": [21, 50, 54, 57, 58, 59], "float16": 21, "url": [21, 35, 59], "http": [21, 31, 35, 50, 53, 57, 58, 59], "cocodataset": 21, "org": [21, 31, 50, 57, 58], "val2017": 21, "000000039769": 21, "jpg": 21, "open": [21, 51, 53, 59], "raw": [21, 50, 52], "pt": [21, 35], "generated_id": 21, "generated_text": 21, "batch_decod": 21, "skip_special_token": 21, "strip": [21, 57], "print": 21, "two": [21, 28, 34, 35, 45, 50, 53, 57, 58], "cat": [21, 57], "lai": 21, "couch": 21, "visual": [21, 57], "how": [21, 35, 43, 50, 55, 57, 58], "mani": [21, 43, 50, 57, 58], "processor_image_token_in_minigpt4": 21, "language_model_input": 21, "batch_siz": [21, 35, 37, 43, 57], "generate_kwarg": 21, "abl": [21, 34, 35, 50, 57, 58], "condit": [21, 43, 50, 57], "shape": [21, 42, 43], "num_channel": 21, "height": [21, 50], "width": 21, "sequence_length": 21, "avoid": [21, 50, 57], "pad": [21, 34, 35], "index": [21, 35, 59], "insert": 21, "flag": 21, "multipl": [21, 43, 50, 57, 59], "num_capt": 21, "build_vision_tow": [22, 23], "vision_tower_cfg": [22, 23], "clipvisiontow": 22, "vision_tow": 22, "delay_load": 22, "nn": [22, 34, 35, 48, 58], "all": [22, 34, 35, 43, 45, 48, 50, 52, 54, 57, 58, 59], "neural": [22, 48], "network": [22, 48, 57], "your": [22, 34, 35, 43, 48, 55, 57, 58], "subclass": [22, 25, 27, 34, 35, 43, 48], "other": [22, 28, 34, 35, 43, 48, 50, 57, 58, 59], "nest": [22, 35, 48], "them": [22, 34, 35, 48, 50, 52, 53, 54, 57, 58, 59], "tree": [22, 48], "you": [22, 34, 35, 43, 48, 50, 52, 53, 54, 57, 58, 59], "submodul": [22, 48], "regular": [22, 48], "attribut": [22, 34, 48], "f": [22, 48], "def": [22, 43, 48, 50, 56, 57, 58], "super": [22, 48], "conv1": [22, 48], "conv2d": [22, 48], "20": [22, 35, 48, 50, 57], "5": [22, 31, 48, 50, 57, 58, 59], "conv2": [22, 48], "x": [22, 42, 48, 50, 57, 58], "relu": [22, 48], "have": [22, 34, 35, 43, 48, 50, 52, 53, 54, 57, 58, 59], "convert": [22, 31, 35, 37, 48, 54], "too": [22, 48, 50], "As": [22, 48, 50, 52, 57, 58], "per": [22, 48, 57], "abov": [22, 48, 50, 52, 58], "parent": [22, 48, 57, 58], "must": [22, 34, 35, 43, 48, 56, 59], "made": [22, 34, 35, 48, 50, 57, 58], "befor": [22, 34, 35, 48, 57, 59], "child": [22, 48, 57], "variabl": [22, 48], "properti": [22, 50], "dummy_featur": 22, "hidden_s": 22, "num_patch": 22, "load_model": 22, "encode_imag": 22, "language_project": 22, "feature_select": 22, "prepare_inputs_labels_for_multimod": 22, "language_model": 22, "copi": [22, 45, 57], "llava": 22, "polish": 22, "its": [24, 35, 50, 57, 59], "pipeline_map": 24, "autopipelin": [24, 56], "design": [24, 59], "get_pipelin": [24, 56], "pipeline_nam": [24, 56], "basetun": [25, 27, 29], "basepipelin": [25, 26, 27, 28, 31], "basealign": [25, 32], "_check_if_align": 25, "reward_model": [25, 32], "_check_if_tun": 27, "packag": [28, 55, 59], "constructor": 28, "three": [28, 50, 52, 57], "relat": [28, 57, 58, 59], "evaluator_arg": 28, "create_dataload": [28, 31], "test": [28, 35, 43, 50, 52, 54, 57, 58, 59], "loader": 28, "iter": [28, 31, 32, 34, 35, 57], "over": [28, 50, 52, 57, 58], "mini": 28, "Then": [28, 43, 54, 57, 58], "write": [28, 50], "log": [28, 35, 50, 53], "consol": 28, "bias": 28, "_match": 28, "predicted_answ": 28, "groundtruth": 28, "accuraci": [28, 50, 57, 58, 59], "verbos": 28, "tunablemodel": [28, 29, 31, 56], "_evaluate_acc_with_acceler": 28, "_evaluate_acc_with_deepspe": 28, "_evaluate_ppl": 28, "_evaluate_nl": 28, "neg": [28, 50, 53, 57, 58, 59], "likelihood": [28, 50, 53], "nll": [28, 50, 55], "n": [28, 50, 53, 59], "sum_": 28, "j": [28, 57, 58], "w_i": 28, "ln": 28, "p": [28, 31], "w_": 28, "context_window": 28, "sampl": [28, 31, 35, 50, 52, 57, 58], "th": 28, "here": [28, 34, 35, 50, 57, 58], "start": [28, 34, 35, 43, 57, 58], "p_": 28, "window_length": 28, "finetuner_arg": 29, "group_text": [29, 56], "model_max_length": [29, 56], "group": [29, 35, 56], "togeth": [29, 35, 57, 59], "form": [29, 34, 35, 57], "transform_dataset_in_plac": 29, "data_col": [29, 34, 35], "rstrip_partial_utf8": 31, "supported_dataset_typ": 31, "inferencer_arg": 31, "batchliz": [31, 37], "dataload": [31, 32, 35, 37], "dataset_s": 31, "100": [31, 35, 43, 58], "remove_image_flag": 31, "chatbot_typ": 31, "mini_gpt": 31, "output_dataset": 31, "stream_infer": 31, "context": [31, 35, 43, 50, 57], "token_per_step": 31, "end_str": 31, "input_dataset": 31, "speculativeinferenc": 31, "draft_model_arg": 31, "ref": 31, "arxiv": [31, 57, 58], "2211": 31, "17192v2": 31, "ab": [31, 57, 58], "17192": 31, "target_model_arg": 31, "draft": [31, 35], "static": [31, 35, 43], "score_to_prob": 31, "score": 31, "top_p": 31, "NOT": 31, "softmax": 31, "probabl": [31, 34, 35, 50, 57, 58], "top": [31, 50, 57], "argmax": 31, "random": [31, 34, 35, 37, 57], "higher": [31, 50, 57], "make": [31, 34, 35, 43, 50, 53, 57, 58, 59], "more": [31, 34, 35, 43, 50, 57, 58, 59], "uniform": 31, "lower": [31, 35, 50], "peakier": 31, "1e": 31, "6": [31, 50, 57, 59], "cumul": 31, "threshold": 31, "adjust": [31, 57, 58], "prob": 31, "num_sampl": 31, "predict_next_token": 31, "num_new_token": 31, "predict": [31, 34, 35, 50], "next": [31, 57], "autoregressive_sampl": 31, "section": [31, 50, 57], "draft_model": 31, "gamma": 31, "verifi": [31, 59], "approxim": 31, "within": 31, "raftalign": 32, "aligner_arg": 32, "raft_aligner_arg": 32, "_initialize_train": 32, "training_arg": [32, 34, 35], "trainer": [32, 34, 35], "_load_dataset": 32, "selected_dataset": 32, "prepar": [32, 35, 53, 57, 58, 59], "everi": [32, 35], "_load_input_dataset": 32, "_clean_text": [32, 57], "_discard_sampl": [32, 57], "_get_batch_dataset_top": 32, "batch_input": 32, "alpha": 32, "iter_id": 32, "16": [32, 43, 58], "48": [32, 43], "infer_batch_s": 32, "8": [32, 50, 57, 59], "generation_kwarg": 32, "_get_batch_dataset_loc": 32, "k": [32, 43, 50, 57, 58], "feed": [32, 35], "reward": [32, 55], "peft": 34, "pefttrain": 34, "featur": [34, 35, 50], "complet": [34, 35, 57, 59], "eval": [34, 35, 57, 58], "loop": [34, 35], "pytorch": [34, 35], "optim": [34, 35, 57, 59], "pretrainedmodel": [34, 35], "model_init": [34, 35], "tip": [34, 35], "work": [34, 35, 43, 50, 57, 58, 59], "still": [34, 35, 43, 50, 57, 58, 59], "own": [34, 35, 50, 52, 53, 57, 58, 59], "long": [34, 35, 50, 52, 57], "same": [34, 35, 57, 58], "tweak": [34, 35], "Will": [34, 35], "basic": [34, 35], "tmp_trainer": [34, 35], "current": [34, 35, 50, 52, 53], "datacol": [34, 35], "element": [34, 35, 50, 59], "train_dataset": [34, 35, 58], "eval_dataset": [34, 35, 58], "default_data_col": [34, 35], "datacollatorwithpad": [34, 35], "otherwis": [34, 35], "iterabledataset": [34, 35], "column": [34, 35], "remov": [34, 35, 57], "note": [34, 35, 50, 53, 59], "fashion": [34, 35], "either": [34, 35, 57], "intern": [34, 35, 50], "ident": [34, 35], "manual": [34, 35, 50], "seed": [34, 35, 37], "epoch": [34, 35, 50, 57, 58], "set_epoch": [34, 35], "rng": [34, 35], "prepend": [34, 35], "kei": [34, 35, 40, 50, 52, 53, 57, 58], "pretrainedtokenizerbas": [34, 35], "preprocess": [34, 35, 58], "along": [34, 35], "easier": [34, 35], "rerun": [34, 35], "interrupt": [34, 35], "callabl": [34, 35], "instanti": [34, 35], "new": [34, 35, 43, 50, 53, 57, 58, 59], "zero": [34, 35], "optuna": [34, 35], "rai": [34, 35], "sigopt": [34, 35], "trial": [34, 35, 50, 57, 58], "architectur": [34, 35], "accord": [34, 35, 50, 57], "hyper": [34, 35, 55], "layer": [34, 35], "count": [34, 35, 50], "inner": [34, 35], "dropout": [34, 35, 43], "compute_metr": [34, 35], "evalpredict": [34, 35], "comput": [34, 35, 43], "callback": [34, 35], "trainercallback": [34, 35], "those": [34, 35, 50, 57], "detail": [34, 35, 43, 50, 53, 55, 57, 58], "want": [34, 35, 53, 57, 58], "remove_callback": [34, 35], "lr_schedul": [34, 35], "lambdalr": [34, 35], "schedul": [34, 35], "adamw": [34, 35], "get_linear_schedule_with_warmup": [34, 35], "preprocess_logits_for_metr": [34, 35], "logit": [34, 35], "right": [34, 35, 50, 57], "step": [34, 35, 53, 55, 57], "onc": [34, 35, 43], "desir": [34, 35, 57, 58], "modif": [34, 35], "reflect": [34, 35, 50], "receiv": [34, 35], "second": [34, 35, 54, 58], "doe": [34, 35, 50, 57, 58, 59], "alwai": [34, 35, 50, 57, 58], "point": [34, 35, 43, 57], "core": [34, 35], "model_wrap": [34, 35], "most": [34, 35, 50, 52, 57, 58], "extern": [34, 35, 50], "case": [34, 35, 43, 50, 54, 57, 58], "wrap": [34, 35], "origin": [34, 35, 50, 54, 57, 58], "again": [34, 35], "distributeddataparallel": [34, 35], "hasn": [34, 35], "been": [34, 35, 43, 50, 57], "is_model_parallel": [34, 35], "switch": [34, 35, 57, 58], "parallel": [34, 35, 43], "mean": [34, 35, 50, 57, 58], "split": [34, 35, 57, 58], "place_model_on_devic": [34, 35], "place": [34, 35, 57, 58], "overridden": [34, 35, 43], "is_in_train": [34, 35], "while": [34, 35, 43, 50, 59], "_save_checkpoint": [34, 35], "_": 34, "folder": 34, "peftsavingcallback": 34, "trainer_callback": [34, 35], "correctli": [34, 50, 57, 58], "_save": [34, 35], "on_train_end": 34, "state": [34, 35, 50, 57], "trainerst": 34, "trainercontrol": 34, "final": [34, 50], "best": [34, 35, 43, 50, 57, 58], "on_epoch_end": 34, "intermedi": 34, "on_sav": 34, "event": [34, 50], "is_torch_greater_or_equal_than_1_10": 35, "is_torch_less_than_1_11": 35, "_is_native_cpu_amp_avail": 35, "default_callback": 35, "default_progress_callback": 35, "is_sagemaker_mp_post_1_10": 35, "skip_first_batch": 35, "training_args_nam": 35, "bin": 35, "trainer_state_nam": 35, "trainer_st": 35, "optimizer_nam": 35, "scheduler_nam": 35, "scaler_nam": 35, "scaler": 35, "rafttrain": 35, "modeling_util": 35, "tokenization_utils_bas": 35, "trainer_util": 35, "add_callback": 35, "In": [35, 50, 53, 54, 57, 58], "member": [35, 57], "pop_callback": 35, "found": [35, 50, 57, 59], "error": 35, "pop": 35, "_move_model_to_devic": 35, "_set_signature_columns_if_need": 35, "_remove_unused_column": 35, "_get_collator_with_removed_column": 35, "unus": 35, "_get_train_sampl": 35, "sampler": 35, "get_train_dataload": 35, "inject": 35, "behavior": 35, "_get_eval_sampl": 35, "get_eval_dataload": 35, "get_test_dataload": 35, "test_dataset": 35, "create_optimizer_and_schedul": 35, "num_training_step": 35, "setup": [35, 55, 57], "learn": [35, 57, 58, 59], "rate": [35, 57], "we": [35, 43, 50, 52, 53, 55, 56, 57, 58, 59], "reason": [35, 57, 58], "well": [35, 50, 57, 59], "someth": [35, 50, 57, 58], "init": 35, "through": [35, 50], "create_optim": 35, "create_schedul": 35, "get_optimizer_cls_and_kwarg": 35, "session": 35, "up": [35, 43, 50, 57, 58], "do": [35, 43, 50, 57, 58, 59], "num_exampl": 35, "access": [35, 50, 54, 59], "exist": 35, "estim": 35, "_hp_search_setup": 35, "hp": 35, "search": [35, 57, 59], "_report_to_hp_search": 35, "_tune_save_checkpoint": 35, "call_model_init": 35, "torch_jit_model_ev": 35, "ipex_optimize_model": 35, "float32": 35, "_wrap_model": 35, "resume_from_checkpoint": 35, "ignore_keys_for_ev": 35, "is_first_tim": 35, "main": [35, 53, 56, 57, 59], "entri": 35, "local": [35, 50, 57], "previou": [35, 57, 58], "equal": [35, 50], "last": [35, 57, 58], "present": [35, 57], "resum": 35, "hyperparamet": 35, "ignor": 35, "gather": [35, 57], "dure": [35, 43, 50, 58], "hide": [35, 57, 58], "deprec": 35, "_one_train": 35, "_inner_training_loop": 35, "serv": [35, 50, 57, 59], "time": [35, 42, 50, 57, 58], "updat": [35, 43, 57, 58], "_get_output_dir": 35, "_load_from_checkpoint": 35, "_load_best_model": 35, "_issue_warnings_after_load": 35, "load_result": 35, "_maybe_log_save_evalu": 35, "tr_loss": 35, "_load_rng_stat": 35, "_load_optimizer_and_schedul": 35, "hyperparameter_search": 35, "hp_space": 35, "compute_object": 35, "n_trial": 35, "direct": [35, 59], "minim": 35, "hpsearchbackend": 35, "hp_name": 35, "bestrun": 35, "launch": 35, "quantiti": 35, "determin": [35, 50], "loss": [35, 58], "sum": 35, "warn": 35, "To": [35, 43, 52, 57, 58, 59], "reiniti": 35, "incompat": 35, "space": [35, 57, 58], "default_hp_space_optuna": 35, "default_hp_space_rai": 35, "default_hp_space_sigopt": 35, "depend": [35, 50, 57, 58], "maxim": [35, 59], "default_compute_object": 35, "greater": [35, 50], "pick": 35, "valid": [35, 43], "training_util": 35, "instal": [35, 53], "create_studi": 35, "see": [35, 43, 50, 57, 58], "readthedoc": 35, "io": [35, 50, 57, 59], "en": [35, 50], "stabl": 35, "refer": [35, 53, 55, 57, 59], "studi": [35, 57, 58], "html": [35, 50, 57], "doc": 35, "latest": 35, "api_doc": 35, "execut": [35, 53], "app": 35, "com": [35, 50, 53, 57, 59], "endpoint": 35, "experi": [35, 50, 57, 59], "run_summari": 35, "watch": 35, "_prepare_input": 35, "potenti": [35, 50], "compute_loss_context_manag": 35, "manag": 35, "autocast_smart_context_manag": 35, "cache_en": 35, "appropri": [35, 50, 57, 58], "autocast": 35, "situat": [35, 50, 57, 58], "training_step": 35, "unpack": 35, "being": [35, 50, 57, 58], "expect": [35, 50], "compute_loss": 35, "return_output": 35, "By": [35, 54, 57, 59], "is_local_process_zero": 35, "machin": [35, 59], "is_world_process_zero": 35, "global": [35, 57], "go": [35, 50, 54, 57], "save_model": 35, "_internal_cal": 35, "reload": 35, "_save_tpu": 35, "state_dict": [35, 46], "store_flo": 35, "_sorted_checkpoint": 35, "checkpoint_prefix": 35, "prefix_checkpoint_dir": 35, "use_mtim": 35, "_rotate_checkpoint": 35, "ignore_kei": 35, "metric_key_prefix": 35, "respons": [35, 37, 50, 57, 58, 59], "wish": 35, "lst": 35, "prefix": [35, 58], "bleu": 35, "eval_bleu": 35, "come": [35, 50], "predictionoutput": 35, "like": [35, 43, 50, 53, 57, 58, 59], "test_bleu": 35, "becaus": [35, 50, 57], "re": [35, 57, 58], "dynam": 35, "concaten": [35, 50], "arrai": [35, 50], "namedtupl": 35, "follow": [35, 43, 52, 53, 57, 58, 59], "np": 35, "ndarrai": 35, "label_id": 35, "evaluation_loop": 35, "prediction_loss_onli": 35, "evalloopoutput": 35, "share": [35, 57, 59], "both": [35, 43, 50, 57, 59], "_nested_gath": 35, "numpi": [35, 37], "_pad_across_process": 35, "pad_index": 35, "recurs": [35, 50], "safe": [35, 50, 57, 58], "prediction_step": 35, "floating_point_op": 35, "oper": [35, 43], "backward": [35, 43], "anoth": [35, 50, 57], "init_git_repo": 35, "at_init": 35, "git": [35, 53, 59], "repo": [35, 53, 57], "hub_model_id": 35, "overwrite_output_dir": 35, "might": [35, 57, 58], "wipe": 35, "out": [35, 43, 50, 57, 58, 59], "create_model_card": 35, "licens": [35, 50, 57], "model_nam": [35, 53], "finetuned_from": 35, "dataset_tag": 35, "dataset_arg": 35, "card": 35, "avail": [35, 50, 52, 53, 59], "applic": [35, 50, 59], "hub": [35, 50], "One": [35, 50], "identifi": 35, "_push_from_checkpoint": 35, "checkpoint_fold": 35, "push_to_hub": 35, "commit_messag": 35, "upload": 35, "push": 35, "finish": [35, 53], "repositori": [35, 50, 59], "track": [35, 57], "progress": 35, "prediction_loop": 35, "_gather_and_numpifi": 35, "_add_sm_patterns_to_gitignor": 35, "sagemak": 35, "pattern": 35, "gitignor": 35, "commonli": [36, 50, 59], "text_only_dataset_descript": 36, "text_only_dataset_detail": 36, "text2text_dataset_descript": 36, "text2text_dataset_detail": 36, "float_only_dataset_descript": 36, "text_only_dataset_long_descrit": 36, "text2text_dataset_long_descrit": 36, "dataset_description_map": 36, "instance_fields_map": 36, "controller_heart_beat_expir": 36, "30": [36, 50, 57, 59], "worker_heart_beat_interv": 36, "15": 36, "logdir": 36, "ignore_index": 36, "default_image_token": 36, "default_image_patch_token": 36, "im_patch": 36, "default_im_start_token": 36, "im_start": 36, "default_im_end_token": 36, "im_end": 36, "set_random_se": 37, "load_data": 37, "file_nam": 37, "len": [37, 50, 56, 58], "shuffl": 37, "answer_extract": 37, "funtion": 37, "plain": [37, 45], "b": [37, 53], "c": [37, 50], "d": [37, 43, 50, 57, 58], "mutipl": 37, "qa": [37, 50], "process_image_flag": 37, "image_flag": 37, "imageher": 37, "hidden_st": [38, 39, 40, 42], "residu": 38, "alibi": [38, 43], "layer_past": [38, 39, 40], "head_mask": [38, 39, 40], "_prepare_attn_mask": 38, "input_shap": [38, 39, 42], "past_key_values_length": [38, 39, 42], "booltensor": 38, "replace_bloom_attn_with_flash_attn": 38, "encoder_hidden_st": 39, "encoder_attention_mask": 39, "ellipsi": 39, "_prepare_decoder_attention_mask": [39, 42], "replace_gpt2_attn_with_flash_attn": 39, "_attn": 40, "queri": 40, "replace_gpt_neo_attn_with_flash_attn": 40, "position_id": 42, "channel": 42, "bsz": 42, "q_len": 42, "replace_llama_attn_with_flash_attn": 42, "experiment": [43, 50], "flashattent": 43, "triton": 43, "dev20221202": 43, "mlir": 43, "seem": [43, 57], "doesn": [43, 50, 57], "head": [43, 57], "dimens": 43, "than": [43, 50, 57, 58], "64": [43, 50, 57, 58, 59], "openai": 43, "ll": [43, 57], "fix": 43, "phil": 43, "tillet": 43, "chang": [43, 53, 57], "causal": 43, "non": [43, 57], "cross": 43, "arbitrari": 43, "seqlen": 43, "128": [43, 58], "32": [43, 58, 59], "bia": 43, "speed": 43, "lse": 43, "instead": [43, 50], "m": [43, 50, 57, 58], "l": 43, "much": 43, "faster": [43, 50], "reduc": [43, 57], "spill": 43, "across": 43, "seqlen_k": 43, "deal": 43, "small": [43, 50], "nhead": 43, "caution": 43, "quit": 43, "robust": [43, 59], "sure": [43, 50, 57, 58], "race": 43, "due": [43, 50, 54], "compil": 43, "a100": 43, "plan": [43, 57], "headdim": 43, "done": [43, 56], "test_flash_attn": 43, "py": [43, 53, 54, 57, 58], "test_flash_attn_triton_race_condit": 43, "ve": [43, 57], "40": [43, 50, 59], "80": [43, 58], "88": [43, 50], "96": [43, 50], "confid": 43, "left": [43, 50], "between": [43, 50], "slower": 43, "slightli": [43, 54], "raggedtensor": 43, "nestedtensor": 43, "_fwd_kernel": 43, "q": [43, 50], "v": 43, "tmp": 43, "softmax_scal": 43, "stride_qb": 43, "stride_qh": 43, "stride_qm": 43, "stride_kb": 43, "stride_kh": 43, "stride_kn": 43, "stride_vb": 43, "stride_vh": 43, "stride_vn": 43, "stride_bb": 43, "stride_bh": 43, "stride_bm": 43, "stride_ob": 43, "stride_oh": 43, "stride_om": 43, "seqlen_q": 43, "seqlen_q_round": 43, "cache_key_seqlen_q": 43, "cache_key_seqlen_k": 43, "bias_typ": 43, "constexpr": 43, "is_caus": 43, "block_headdim": 43, "even_m": 43, "even_n": 43, "even_headdim": 43, "block_m": 43, "block_n": 43, "_bwd_preprocess_do_o_dot": 43, "delta": 43, "stride_dob": 43, "stride_doh": 43, "stride_dom": 43, "_bwd_store_dk_dv": 43, "dk_ptr": 43, "dv_ptr": 43, "dk": 43, "dv": 43, "offs_n": 43, "offs_d": 43, "_bwd_kernel_one_col_block": 43, "start_n": 43, "dq": 43, "stride_dqm": 43, "stride_dkn": 43, "stride_dvn": 43, "atomic_add": 43, "init_to_zero": 43, "_bwd_kernel": 43, "stride_dqb": 43, "stride_dqh": 43, "stride_dkb": 43, "stride_dkh": 43, "stride_dvb": 43, "stride_dvh": 43, "sequence_parallel": 43, "_flash_attn_forward": 43, "_flash_attn_backward": 43, "o": [43, 50, 56], "flashattnqkvpackedfunc": 43, "autograd": 43, "op": 43, "appli": [43, 50, 52, 57, 59], "directli": [43, 50, 53, 54, 59], "ensur": 43, "ctx": 43, "gradcheck": 43, "extend": 43, "xdoctest": 43, "env": 43, "torch_doctest_autograd": 43, "exp": 43, "staticmethod": 43, "save_for_backward": 43, "grad_output": 43, "saved_tensor": 43, "skip": [43, 57], "qkv": 43, "3": [43, 50, 52, 53, 55, 59], "broadcast": 43, "would": [43, 50, 57, 58], "formula": 43, "differenti": 43, "alia": 43, "vjp": 43, "were": [43, 57], "gradient": 43, "w": 43, "r": 43, "correspond": [43, 50, 52], "grad": 43, "needs_input_grad": 43, "flash_attn_qkvpacked_func": 43, "flashattnkvpackedfunc": 43, "kv": 43, "flash_attn_kvpacked_func": 43, "flashattnfunc": 43, "flash_attn_func": 43, "separatorstyl": 45, "kwd": 45, "enum": 45, "separ": [45, 53], "style": [45, 50], "mpt": 45, "llama_2": 45, "convers": [45, 50, 57, 59], "keep": [45, 57], "histori": [45, 50, 57, 58], "system": 45, "role": [45, 50, 57], "offset": 45, "sep": 45, "sep2": 45, "unknown": 45, "skip_next": 45, "get_prompt": 45, "append_messag": 45, "get_imag": 45, "return_pil": 45, "to_gradio_chatbot": 45, "conv_vicuna_v0": 45, "conv_vicuna_v1": 45, "conv_llama_2": 45, "conv_llava_llama_2": 45, "conv_mpt": 45, "conv_llava_plain": 45, "conv_llava_v0": 45, "conv_llava_v0_mmtag": 45, "conv_llava_v1": 45, "conv_llava_v1_mmtag": 45, "default_convers": 45, "conv_templ": 45, "update_custom_config": 46, "load_llava_pretrain_model": 46, "checkpoint_path": 46, "adapt_llava_model_to_lmflow_typ": 46, "condenserotaryembed": 48, "dim": 48, "pi_ratio": 48, "ntk_ratio": 48, "max_position_embed": 48, "2048": 48, "10000": [48, 57, 58], "seq_len": 48, "replace_llama_with_condens": 48, "9": [50, 53, 59], "larg": [50, 57, 59], "huge": 50, "challeng": [50, 57, 58], "sinc": [50, 52, 57], "breakthrough": 50, "chatgpt": [50, 59], "On": 50, "hand": [50, 57, 59], "research": [50, 57], "engin": [50, 52], "reliabl": [50, 57, 59], "compar": [50, 57, 58, 59], "decid": [50, 53], "certain": [50, 57, 58], "scenario": 50, "monitor": 50, "issu": [50, 54, 57, 59], "forget": 50, "recent": 50, "vicuna": 50, "introduc": [50, 57, 59], "comparison": [50, 57], "human": [50, 53, 57, 58, 59], "chatbot": 50, "arena": 50, "pioneer": 50, "invok": 50, "gpt": [50, 57, 58, 59], "expens": 50, "neither": 50, "scalabl": [50, 59], "nor": 50, "articl": 50, "cheap": 50, "easi": [50, 57, 58], "aspect": 50, "everyon": 50, "commun": [50, 57, 59], "toolkit": [50, 57, 59], "our": [50, 52, 53, 54, 55, 56, 57, 59], "corpu": 50, "itself": 50, "abil": [50, 59], "round": [50, 57], "math": 50, "problem": [50, 55, 57, 58], "solv": 50, "plai": 50, "corpora": 50, "quantit": 50, "idea": [50, 57, 58], "behind": 50, "correl": 50, "essai": 50, "understand": [50, 57, 59], "chess": 50, "master": 50, "memor": 50, "endgam": 50, "chessboard": 50, "besid": 50, "similar": [50, 54, 57], "ppl": 50, "nevertheless": 50, "intrins": 50, "induc": 50, "unfair": 50, "smaller": [50, 57], "vocabulari": 50, "inher": 50, "longer": 50, "level": [50, 59], "thu": 50, "advantag": 50, "involv": [50, 57, 58], "good": [50, 54, 57, 58], "find": [50, 57, 58], "tabl": [50, 53, 57], "tradit": [50, 57], "winogrand": 50, "boolq": 50, "arc_": 50, "hellaswag": 50, "piqa": 50, "obqa": 50, "arc_c": 50, "averag": [50, 59], "bloom": [50, 59], "3b": [50, 57, 58], "58": [50, 57, 58, 59], "7": [50, 57, 59], "61": [50, 59], "59": [50, 59], "52": [50, 57, 58], "70": [50, 59], "42": 50, "53": 50, "1b": 50, "62": 50, "65": [50, 57, 58, 59], "73": [50, 59], "35": [50, 59], "33": 50, "56": [50, 59], "9b": 50, "66": [50, 59], "67": [50, 59], "76": 50, "37": [50, 59], "34": 50, "13b": [50, 58], "69": [50, 57, 58, 59], "39": [50, 57, 59], "llama": [50, 55, 57, 58, 59], "78": [50, 59], "41": 50, "68": [50, 59], "74": [50, 59], "79": [50, 57, 58], "44": [50, 59], "86": 50, "228": 50, "245": 50, "134": 50, "135": 50, "85": [50, 59], "215": 50, "81": [50, 58], "237": 50, "130": 50, "129": 50, "200": 50, "224": 50, "125": [50, 57], "124": 50, "82": 50, "198": 50, "220": 50, "97": 50, "123": 50, "167": 50, "71": [50, 57, 58], "214": 50, "121": 50, "113": 50, "153": 50, "207": 50, "119": 50, "57": [50, 59], "83": 50, "109": 50, "figur": [50, 57], "roughli": 50, "magnitud": 50, "gap": 50, "entail": 50, "comprehens": 50, "summar": 50, "limit": 50, "demonstr": [50, 57, 59], "partial": 50, "sheet": 50, "0501": 50, "optimalscal": [50, 57, 59], "github": [50, 53, 57, 59], "task_guid": 50, "robin": 50, "popular": [50, 57, 58], "try": [50, 57, 58], "onlin": 50, "demo": 50, "especi": 50, "observ": [50, 57, 58, 59], "foundat": [50, 57, 59], "obtain": [50, 54, 57, 58, 59], "gain": [50, 57, 59], "achiev": [50, 57, 59], "better": [50, 57, 59], "en_multi_round_chat": 50, "en_singe_round_chat": 50, "188": 50, "213": 50, "164": 50, "181": 50, "172": 50, "163": 50, "184": 50, "173": 50, "155": 50, "175": 50, "165": 50, "150": 50, "170": 50, "160": 50, "146": 50, "qualit": 50, "turn": [50, 57, 58], "effortlessli": 50, "slight": [50, 58], "mistak": [50, 57], "sometim": [50, 57], "item": [50, 53], "mexican": 50, "food": [50, 57], "cuisin": 50, "recommend": [50, 57, 58], "omit": 50, "r1": 50, "capit": 50, "usa": 50, "unit": [50, 57], "washington": 50, "district": 50, "columbia": 50, "locat": 50, "east": 50, "coast": [50, 57], "countri": 50, "northern": 50, "part": 50, "maryland": 50, "georg": 50, "presid": 50, "feder": 50, "administ": 50, "govern": 50, "citi": 50, "home": [50, 57, 58], "nation": [50, 57], "landmark": 50, "white": 50, "hous": [50, 57, 58], "capitol": 50, "build": [50, 57, 58, 59], "suprem": 50, "court": 50, "museum": 50, "monument": 50, "cultur": [50, 57, 58], "institut": 50, "virginia": 50, "r2": 50, "scene": 50, "restaur": 50, "american": 50, "classic": 50, "There": [50, 57, 58], "dish": [50, 57], "hamburg": 50, "hot": [50, 57], "dog": 50, "appl": 50, "pie": 50, "seafood": 50, "chesapeak": 50, "bai": 50, "known": 50, "fresh": 50, "crab": 50, "cake": 50, "shrimp": 50, "oyster": 50, "ethnic": 50, "popul": 50, "chines": 50, "japanes": 50, "korean": 50, "barbecu": 50, "pull": 50, "pork": 50, "rib": 50, "brisket": 50, "donut": 50, "famou": 50, "happi": [50, 57, 58], "shop": 50, "varieti": 50, "flavor": 50, "street": 50, "truck": 50, "stand": 50, "falafel": 50, "kebab": 50, "taco": 50, "These": 50, "few": [50, 57, 59], "wide": [50, 59], "rang": [50, 58, 59], "visit": 50, "soul": 50, "southern": 50, "bold": 50, "hearti": 50, "portion": 50, "fri": [50, 57], "chicken": 50, "collard": 50, "green": 50, "macaroni": 50, "chees": 50, "ethiopian": 50, "spici": [50, 57], "injera": 50, "sourdough": 50, "flatbread": 50, "wat": 50, "veget": [50, 57], "stew": 50, "kitfo": 50, "meat": [50, 57], "pasta": 50, "bbq": 50, "thrive": 50, "slow": 50, "cook": [50, 57], "side": [50, 57], "spot": 50, "ben": 50, "chili": 50, "bowl": 50, "pete": 50, "vegetarian": 50, "smoke": 50, "barrel": 50, "diplomaci": 50, "culinari": 50, "indian": 50, "r3": 50, "fifth": 50, "mention": 50, "usual": 50, "flame": 50, "heat": [50, 57, 58], "coal": 50, "often": [50, 57], "marin": 50, "sauc": [50, 57], "coleslaw": 50, "bake": [50, 57], "bean": 50, "corn": 50, "cob": 50, "pit": 50, "smokehous": 50, "joint": 50, "salt": [50, 57], "sovereign": 50, "offer": [50, 57], "delici": 50, "margarita": 50, "adam": 50, "morgan": 50, "authent": 50, "year": [50, 57, 59], "al": 50, "pastor": 50, "grill": 50, "enchilada": 50, "fill": 50, "tortilla": 50, "chile": 50, "relleno": 50, "stuf": 50, "pepper": 50, "el": 50, "comal": 50, "cozi": 50, "littl": 50, "neighborhood": 50, "mole": 50, "rich": 50, "blend": 50, "spice": 50, "chocol": [50, 57], "de": 50, "carnita": 50, "crispi": 50, "queso": 50, "casa": 50, "oaxaca": 50, "upscal": 50, "shaw": 50, "menu": [50, 57], "modern": 50, "cevich": 50, "fish": 50, "lime": 50, "juic": 50, "negro": 50, "dark": 50, "nogada": 50, "poblano": 50, "walnut": 50, "honei": 50, "king": 50, "chain": 50, "area": [50, 59], "burrito": 50, "afford": [50, 57, 58], "price": 50, "carn": 50, "asada": 50, "quesadilla": 50, "lo": 50, "No": 50, "casual": 50, "adobada": 50, "real": 50, "collect": [50, 57, 59], "183": 50, "english": 50, "total": 50, "447": 50, "break": 50, "pair": [50, 52, 53], "q1": 50, "a1": 50, "q2": 50, "a2": 50, "q3": 50, "a3": 50, "ouptut": 50, "common": [50, 52, 59], "sens": 50, "acquir": [50, 59], "factual": 50, "knowledg": [50, 59], "properli": [50, 57], "regard": 50, "degrad": 50, "competit": 50, "arc_easi": 50, "60": [50, 59], "72": [50, 59], "38": 50, "55": [50, 58, 59], "63": [50, 59], "77": 50, "75": [50, 59], "254": 50, "89": 50, "266": 50, "147": 50, "106": 50, "219": 50, "258": 50, "151": 50, "105": 50, "141": 50, "95": 50, "262": 50, "149": 50, "140": 50, "240": 50, "139": 50, "surpris": 50, "actual": [50, 57, 58], "consequ": 50, "hallucin": 50, "tend": [50, 57], "give": [50, 57, 58], "plausibl": 50, "incorrect": 50, "irrelev": 50, "explan": 50, "phenomenon": [50, 57, 58], "attempt": 50, "fit": 50, "suffer": 50, "less": 50, "conjectur": 50, "improv": [50, 57, 58, 59], "brought": 50, "qualiti": [50, 57], "sharegpt": 50, "900mb": 50, "wa": [50, 57, 58], "600mb": 50, "suggest": [50, 57], "stage": 50, "critic": 50, "monei": 50, "compet": [50, 59], "show": [50, 55, 57, 58], "possess": 50, "friend": 50, "door": 50, "lock": 50, "smell": 50, "ga": 50, "window": [50, 57], "quickli": [50, 59], "possibl": 50, "fire": [50, 57, 58], "depart": [50, 57], "compani": 50, "flammabl": 50, "danger": 50, "even": [50, 58], "deadli": 50, "ventil": 50, "could": [50, 57, 58], "caus": [50, 57, 58], "explos": 50, "escap": 50, "cannot": 50, "stai": [50, 57], "calm": 50, "wait": 50, "arriv": 50, "injuri": 50, "damag": [50, 57, 58, 59], "yourself": 50, "addition": [50, 57, 58], "illeg": 50, "enter": 50, "permiss": 50, "homeown": 50, "locksmith": 50, "assist": [50, 53, 57, 58], "unabl": 50, "emerg": 50, "servic": 50, "polic": 50, "meantim": 50, "lighter": 50, "leak": 50, "evacu": 50, "immedi": 50, "inde": 50, "injur": [50, 57], "bring": [50, 57], "my": [50, 57, 58], "pet": 50, "ferret": 50, "beauti": 50, "pacif": 50, "island": 50, "attend": 50, "icml": 50, "sorri": 50, "am": [50, 57], "awar": [50, 59], "polici": [50, 57], "confer": 50, "organ": [50, 57, 58], "author": [50, 59], "procedur": [50, 57, 58], "permit": 50, "proper": 50, "carri": [50, 57, 58], "diseas": 50, "peopl": [50, 57, 58, 59], "toxoplasmosi": 50, "salmonellosi": 50, "priorit": 50, "health": 50, "safeti": [50, 57], "crowd": 50, "held": [50, 59], "hawaii": 50, "strictli": 50, "prohibit": 50, "carrier": 50, "rabi": 50, "viru": 50, "eleuth": [50, 53], "ai": [50, 57, 58, 59], "lm": [50, 55], "har": [50, 53], "eleutherai": [50, 53, 57, 58], "loyal": 50, "obei": 50, "ethic": 50, "legal": [50, 59], "gpt4_en_instruct": 50, "alpaca": [50, 52, 54], "222": 50, "211": 50, "206": 50, "180": 50, "quicksort": 50, "ye": [50, 57, 58], "algorithm": [50, 55], "arr": 50, "pivot": 50, "middl": 50, "partit": 50, "sub": 50, "sort": [50, 57, 58], "unsort": 50, "complex": 50, "although": [50, 57, 58], "practic": 50, "carefulli": [50, 57], "chosen": [50, 53, 57, 58], "subarrai": 50, "produc": 50, "synonym": 50, "word": [50, 57], "down": 50, "advers": 50, "difficulti": 50, "hardship": 50, "troubl": [50, 57, 58], "misfortun": 50, "hard": [50, 57, 58], "unpleas": 50, "circumst": [50, 57, 58], "connot": 50, "difficult": 50, "hostil": 50, "factor": [50, 57], "enemi": 50, "natur": [50, 59], "disast": [50, 57], "mild": 50, "inconveni": 50, "major": 50, "setback": 50, "distress": 50, "financi": 50, "bad": 50, "luck": 50, "ill": 50, "fate": 50, "econom": 50, "social": 50, "struggl": 50, "oppress": 50, "afflict": 50, "calam": 50, "tribul": 50, "10": [50, 57, 58], "describ": 50, "impli": 50, "intens": [50, 57], "battl": 50, "conflict": 50, "obstacl": 50, "injustic": 50, "proceed": 50, "persecut": [50, 57, 58], "order": 50, "project": [50, 57], "000": 50, "filter": [50, 58], "767": 50, "effect": [50, 57, 59], "remain": 50, "nonsens": 50, "incomplet": 50, "domain": [50, 59], "chemistri": 50, "biologi": [50, 59], "fail": 50, "par": 50, "surpass": [50, 59], "now": [50, 54, 57], "Its": [50, 52, 59], "essenti": 50, "lmsy": 50, "benchmark": [51, 55], "llm": [51, 57, 59], "cd": [52, 53, 54, 57], "sh": [52, 53, 54, 57, 58], "replac": [52, 57, 58], "strongli": 52, "encourag": [52, 57], "techniqu": [52, 59], "below": [52, 53, 59], "specifi": [52, 53, 57], "path_to_dataset": 52, "data_1": 52, "data_2": 52, "another_data": 52, "shall": [52, 59], "four": [52, 58], "key_3": 52, "key_4": 52, "value_3": 52, "interpret": 52, "sample_text_1": 52, "sample_text_2": 52, "sample_text_3": 52, "example_dataset": 52, "train_50": 52, "mostli": 52, "sample_input_1": 52, "sample_output_1": 52, "sample_input_2": 52, "sample_output_2": 52, "sample_input_3": 52, "sample_output_3": 52, "test_13": 52, "easili": [53, 59], "fork": 53, "clone": [53, 59], "usernam": 53, "checkout": [53, 57], "conda": [53, 59], "y": [53, 59], "activ": [53, 57, 59], "mpi4pi": [53, 59], "pip": [53, 59], "notic": 53, "mkdir": 53, "mv": 53, "info": 53, "local_datset_group_map": 53, "local_datset_map": 53, "local_datset_answertype_map": 53, "combin": 53, "task_combin": 53, "task_1": 53, "task_2": 53, "rememb": [53, 57], "tee": 53, "log_dir": 53, "err": 53, "integr": 53, "benchamrk": 53, "command": [53, 57, 58, 59], "simpli": [53, 57], "lm_eval_dataset_map": 53, "pleas": [53, 57, 59], "exact": [53, 57], "similarli": 53, "copyright": 54, "facebookresearch": 54, "offici": 54, "hf": 54, "convert_llama_weights_to_hf": 54, "input_dir": 54, "model_s": 54, "enjoi": [54, 57, 58], "With": 54, "output_model": [54, 57], "run_evaluation_with_lora": 54, "cuda_visible_devic": 54, "diff": 54, "textonli": 55, "sft": 55, "introduct": 55, "merg": 55, "overview": 55, "guid": [55, 57, 58], "registr": 55, "sy": 56, "hfargumentpars": 56, "tunable_model": 56, "pars": 56, "pipelineargu": 56, "parser": 56, "argv": 56, "endswith": 56, "let": [56, 57, 58, 59], "parse_json_fil": 56, "json_fil": 56, "abspath": 56, "parse_args_into_dataclass": 56, "todo": 56, "main_process_first": 56, "desc": 56, "lm_dataset": 56, "tuned_model": 56, "remark": [57, 58, 59], "built": 57, "whose": 57, "commerci": [57, 59], "reinforc": [57, 58], "feedback": [57, 58], "rlhf": [57, 58], "instructgpt": [57, 58, 59], "paper": [57, 58], "2203": [57, 58], "02155": [57, 58], "rank": [57, 58], "neo": [57, 58], "dahoa": [57, 58], "hh": [57, 58], "consist": [57, 58], "particular": [57, 58, 59], "prefer": [57, 58], "reject": [57, 58], "112k": [57, 58], "12": [57, 58], "5k": [57, 58], "what": [57, 58], "kind": [57, 58], "nois": [57, 58], "did": [57, 58], "dinosaur": [57, 58], "didn": [57, 58], "live": [57, 58], "realli": [57, 58], "sai": [57, 58], "guess": [57, 58], "lot": [57, 58], "read": [57, 58], "amount": [57, 58], "imagin": [57, 58], "cant": [57, 58], "stuff": [57, 58], "know": [57, 58], "facilit": 57, "reformul": 57, "ad": [57, 58], "charact": 57, "repli": 57, "hh_rlhf": [57, 58], "xiongwei": 57, "hh_rlhf_sft": 57, "bui": [57, 58], "protect": [57, 58], "cell": [57, 58], "phone": [57, 58], "pocket": [57, 58], "purs": [57, 58], "But": [57, 58], "quick": [57, 58], "interact": [57, 58], "harm": [57, 58], "screen": [57, 58], "thing": [57, 58], "off": [57, 58], "won": [57, 58], "anyth": [57, 58], "aren": [57, 58], "thank": [57, 58], "me": [57, 58], "welcom": [57, 58, 59], "salam": [57, 58], "witch": [57, 58], "look": [57, 58], "book": [57, 58], "witchcraft": [57, 58], "histor": [57, 58], "salem": [57, 58], "1692": [57, 58], "interest": [57, 58, 59], "coloni": [57, 58], "america": [57, 58], "excel": [57, 58], "religion": [57, 58], "declin": [57, 58], "magic": [57, 58], "belief": [57, 58], "sixteenth": [57, 58], "seventeenth": [57, 58], "centuri": [57, 58], "england": [57, 58], "keith": [57, 58], "thoma": [57, 58], "otherworld": [57, 58], "anthropologi": [57, 58], "superstit": [57, 58], "jack": [57, 58], "goodi": [57, 58], "popish": [57, 58], "plot": [57, 58], "prelat": [57, 58], "everett": [57, 58], "edit": [57, 58], "run_finetun": [57, 58], "modifi": [57, 58], "project_dir": [57, 58], "num_train_epoch": 57, "learning_r": 57, "2e": 57, "per_device_train_batch_s": 57, "run_finetune_with_lora": [57, 58], "fortun": [57, 58], "former": [57, 58], "rm": [57, 58], "hh_rlhf_rm_train": 57, "heater": [57, 58], "hazard": [57, 58], "tell": [57, 58], "fireplac": [57, 58], "room": [57, 58], "materi": [57, 58], "feel": [57, 58], "touch": [57, 58], "fuel": [57, 58], "surround": [57, 58], "That": [57, 58], "glad": [57, 58], "teach": [57, 58, 59], "kid": [57, 58], "fort": [57, 58], "Or": [57, 58], "elabor": [57, 58], "exactli": [57, 58], "mayb": [57, 58], "simplest": [57, 58], "pile": [57, 58], "furnitur": [57, 58], "taller": [57, 58], "sturdier": [57, 58], "fun": [57, 58], "explor": [57, 58], "run_reward_model": [57, 58], "superior": 57, "root": 57, "usr_nam": 57, "hh_rlhf_rm_sft_gptneo_2_7b": 57, "1659": 57, "3e": 57, "eval_step": 57, "400": 57, "load_dataset": [57, 58], "24": [57, 58, 59], "merge_lora": 57, "readi": 57, "clearli": 57, "heavili": 57, "influenc": 57, "data_collect": 57, "subsect": 57, "gpt2": 57, "1024": 57, "overwritten": 57, "reader": 57, "rl": 57, "environ": 57, "far": 57, "perfect": 57, "drl": 57, "ppo": 57, "exploit": 57, "theses": 57, "imperfect": 57, "attack": 57, "record": [57, 58], "heavi": 57, "burden": 57, "therefor": [57, 59], "256": 57, "discard": 57, "resourc": 57, "82147": 57, "2k": 57, "adopt": 57, "post": [57, 58], "stext": 57, "reward_model_or_path": 57, "weqweasda": 57, "hh_rlhf_rm": 57, "get_reward_funct": 57, "run_raft_align": 57, "hh_rlhf_llama": 57, "rlhf_prompt": 57, "hh_rlhf_raft_align": 57, "smoothli": 57, "increas": [57, 58], "signific": [57, 58, 59], "drop": 57, "distinct": 57, "22": 57, "examin": 57, "occasion": 57, "detect": 57, "high": 57, "wors": 57, "eventu": 57, "half": 57, "noisi": 57, "notat": 57, "retrain": 57, "allevi": 57, "goal": [57, 59], "disabl": 57, "curv": 57, "journei": 57, "randomli": 57, "redund": 57, "suspect": 57, "src": 57, "clean_text": 57, "discard_sampl": 57, "advanc": 57, "contribut": 57, "girlfriend": 57, "tri": 57, "remind": 57, "her": 57, "nice": 57, "tast": 57, "compliment": 57, "kitchen": 57, "she": 57, "appreci": 57, "recip": 57, "great": 57, "spend": 57, "homework": 57, "ask": 57, "why": 57, "motiv": 57, "extra": 57, "privileg": 57, "video": 57, "game": 57, "altern": 57, "incentiv": 57, "grade": 57, "clear": 57, "incent": 57, "meaning": 57, "said": 57, "veri": 57, "think": 57, "exchang": 57, "power": [57, 59], "weather": 57, "strongest": 57, "hurrican": 57, "ever": 57, "hit": 57, "u": [57, 59], "katrina": 57, "2005": 57, "1938": 57, "bigger": 57, "stronger": 57, "date": 57, "strong": 57, "storm": 57, "1935": 57, "florida": 57, "review": 57, "had": 57, "categori": 57, "800": 57, "death": 57, "caribbean": 57, "led": 57, "creation": 57, "divis": 57, "ocean": 57, "atmospher": 57, "administr": 57, "firefight": 57, "occup": 57, "definit": 57, "criteria": 57, "judg": 57, "hero": 57, "who": [57, 59], "fight": 57, "rescu": 57, "accid": 57, "sick": 57, "educ": 57, "restor": 57, "societi": 57, "girl": 57, "scout": 57, "samoa": 57, "cooki": 57, "okai": 57, "cup": 57, "flour": 57, "teaspoon": 57, "soda": 57, "powder": 57, "sugar": 57, "melt": 57, "butter": 57, "egg": 57, "milk": 57, "chip": 57, "miniatur": 57, "chop": 57, "peanut": 57, "pecan": 57, "heard": 57, "videogam": 57, "metal": 57, "gear": 57, "solid": 57, "phantom": 57, "pain": 57, "releas": [57, 59], "unfinish": 57, "seri": 57, "creator": 57, "hideo": 57, "kojima": 57, "konami": 57, "unusu": 57, "director": 57, "vigil": 57, "overse": 57, "opportun": 57, "he": 57, "hi": 57, "studio": 57, "product": [57, 59], "strand": 57, "2020": 57, "brand": 57, "knive": 57, "victorinox": 57, "w\u00fcsthof": 57, "host": 57, "guest": 57, "drink": 57, "rwandan": 57, "mizuzu": 57, "deep": 57, "plantain": 57, "oil": 57, "skillet": 57, "until": 57, "golden": 57, "brown": 57, "jfk": 57, "greatest": 57, "accomplish": 57, "civil": 57, "peac": 57, "corp": 57, "propon": 57, "scienc": 57, "technologi": 57, "reform": 57, "impact": [57, 58], "kennedi": 57, "leader": 57, "inspir": 57, "vision": 57, "care": 57, "poor": 57, "mainstream": 57, "foreign": 57, "univers": 57, "supervisor": 57, "incorrectli": 57, "explain": 57, "someon": 57, "respect": 57, "diplomat": 57, "willing": 57, "him": 57, "dedic": 57, "employe": 57, "succe": 57, "capabl": 57, "leadership": 57, "talk": 57, "dai": 57, "hate": 57, "hm": 57, "frustrat": 57, "person": 57, "patient": 57, "isn": 57, "malfunct": 57, "softwar": 57, "bug": 57, "hardwar": 57, "outag": 57, "thankfulli": 57, "resolv": 57, "restart": 57, "10k": 58, "12k": 58, "illustr": 58, "select": 58, "percentag": 58, "build_dataset": 58, "assum": [58, 59], "answer_posit": 58, "answer_neg": 58, "tokenized_po": 58, "tokenized_neg": 58, "chosen_input_id": 58, "chosen_attention_mask": 58, "rejected_input_id": 58, "rejected_attention_mask": 58, "data_fil": 58, "lambda": 58, "512": 58, "idx_gap": 58, "logsigmoid": 58, "chosen_reward": 58, "rejected_reward": 58, "appear": 58, "crucial": [58, 59], "success": 58, "underw": 58, "surprisingli": 58, "moreov": [58, 59], "overfit": 58, "84": 58, "wandb": 58, "ianz2020": 58, "bg677mxa": 58, "ka9v1ywd": 58, "lntwmcyd": 58, "weixiong5237": 58, "t3uwm8yp": 58, "p2ju3r1a": 58, "8fc1rcf8": 58, "7oemwynu": 58, "toolbox": 59, "friendli": 59, "speedi": 59, "entir": 59, "backbon": 59, "galactica": 59, "light": 59, "extrem": 59, "33b": 59, "25mb": 59, "storag": 59, "orient": 59, "whole": 59, "expans": 59, "except": 59, "capac": 59, "attain": 59, "intellig": 59, "convent": 59, "despit": 59, "grow": 59, "cater": 59, "maintain": 59, "lightweight": 59, "thoughtfulli": 59, "tool": 59, "publicli": 59, "thoroughli": 59, "enhanc": 59, "profici": 59, "medicin": 59, "mathemat": 59, "subject": 59, "matter": 59, "medic": 59, "emphas": 59, "pubmedqa": 59, "medmcqa": 59, "medqa": 59, "usml": 59, "50": 59, "expert": 59, "87": 59, "90": 59, "175b": 59, "46": 59, "54": 59, "27": 59, "18": 59, "43": 59, "25": 59, "49": 59, "51": 59, "mmlu": 59, "anatomi": 59, "clinic": 59, "colleg": 59, "genet": 59, "profession": 59, "36": 59, "30b": 59, "26": 59, "23": 59, "120b": 59, "21": 59, "176b": 59, "29": 59, "gopher": 59, "280b": 59, "gpt3": 59, "constraint": 59, "unseen": 59, "incorpor": 59, "cue": 59, "relev": 59, "approach": 59, "unlock": 59, "jsonl": 59, "readm": 59, "blog": 59, "excit": 59, "announc": 59, "upcom": 59, "workflow": 59, "among": 59, "aim": 59, "democrat": 59, "platform": 59, "skill": 59, "anyon": 59, "particip": 59, "join": 59, "beginn": 59, "believ": 59, "benefit": 59, "vibrant": 59, "innov": 59, "misc": 59, "kashun": 59, "titl": 59, "publish": 59, "journal": 59, "howpublish": 59, "streamlin": 59, "intend": 59, "li": 59, "sole": 59, "guarante": 59, "compon": 59, "risk": 59, "liabil": 59, "associ": 59, "technic": 59, "advic": 59, "indirect": 59, "incident": 59, "consequenti": 59, "improp": 59, "highlight": 59, "probabilist": 59, "seek": 59, "reli": 59, "outcom": 59, "account": 59, "relianc": 59, "submit": 59}, "objects": {"": [[9, 0, 0, "-", "lmflow"]], "lmflow": [[9, 1, 1, "", "__version__"], [5, 0, 0, "-", "args"], [7, 0, 0, "-", "datasets"], [9, 1, 1, "", "internal_version"], [16, 0, 0, "-", "models"], [30, 0, 0, "-", "pipeline"], [44, 0, 0, "-", "utils"], [49, 0, 0, "-", "version"]], "lmflow.args": [[5, 2, 1, "", "AutoArguments"], [5, 2, 1, "", "BenchmarkingArguments"], [5, 2, 1, "", "DatasetArguments"], [5, 2, 1, "", "EvaluatorArguments"], [5, 2, 1, "", "FinetunerArguments"], [5, 2, 1, "", "InferencerArguments"], [5, 1, 1, "", "MODEL_CONFIG_CLASSES"], [5, 1, 1, "", "MODEL_TYPES"], [5, 2, 1, "", "ModelArguments"], [5, 2, 1, "", "MultiModalDatasetArguments"], [5, 1, 1, "", "PIPELINE_ARGUMENT_MAPPING"], [5, 2, 1, "", "RaftAlignerArguments"], [5, 2, 1, "", "VisModelArguments"]], "lmflow.args.AutoArguments": [[5, 3, 1, "", "get_pipeline_args_class"]], "lmflow.args.BenchmarkingArguments": [[5, 4, 1, "", "dataset_name"], [5, 4, 1, "", "lm_evaluation_metric"]], "lmflow.args.DatasetArguments": [[5, 3, 1, "", "__post_init__"], [5, 4, 1, "", "block_size"], [5, 4, 1, "", "customized_cache_dir"], [5, 4, 1, "", "dataset_config_name"], [5, 4, 1, "", "dataset_name"], [5, 4, 1, "", "dataset_path"], [5, 4, 1, "", "disable_group_texts"], [5, 4, 1, "", "group_texts_batch_size"], [5, 4, 1, "", "is_custom_dataset"], [5, 4, 1, "", "keep_linebreaks"], [5, 4, 1, "", "max_eval_samples"], [5, 4, 1, "", "max_train_samples"], [5, 4, 1, "", "overwrite_cache"], [5, 4, 1, "", "preprocessing_num_workers"], [5, 4, 1, "", "streaming"], [5, 4, 1, "", "test_file"], [5, 4, 1, "", "train_file"], [5, 4, 1, "", "validation_file"], [5, 4, 1, "", "validation_split_percentage"]], "lmflow.args.EvaluatorArguments": [[5, 4, 1, "", "answer_type"], [5, 4, 1, "", "deepspeed"], [5, 4, 1, "", "evaluate_block_size"], [5, 4, 1, "", "inference_batch_size_per_device"], [5, 4, 1, "", "local_rank"], [5, 4, 1, "", "max_new_tokens"], [5, 4, 1, "", "metric"], [5, 4, 1, "", "mixed_precision"], [5, 4, 1, "", "output_dir"], [5, 4, 1, "", "prompt_structure"], [5, 4, 1, "", "random_seed"], [5, 4, 1, "", "random_shuffle"], [5, 4, 1, "", "repetition_penalty"], [5, 4, 1, "", "temperature"], [5, 4, 1, "", "use_accelerator_for_evaluator"], [5, 4, 1, "", "use_wandb"]], "lmflow.args.FinetunerArguments": [[5, 4, 1, "", "eval_dataset_path"], [5, 4, 1, "", "finetune_part"], [5, 4, 1, "", "remove_unused_columns"], [5, 4, 1, "", "save_language_projection"]], "lmflow.args.InferencerArguments": [[5, 4, 1, "", "deepspeed"], [5, 4, 1, "", "device"], [5, 4, 1, "", "do_sample"], [5, 4, 1, "", "local_rank"], [5, 4, 1, "", "max_new_tokens"], [5, 4, 1, "", "mixed_precision"], [5, 4, 1, "", "random_seed"], [5, 4, 1, "", "repetition_penalty"], [5, 4, 1, "", "temperature"]], "lmflow.args.ModelArguments": [[5, 3, 1, "", "__post_init__"], [5, 4, 1, "id0", "arch_type"], [5, 4, 1, "", "bits"], [5, 4, 1, "", "cache_dir"], [5, 4, 1, "", "config_name"], [5, 4, 1, "", "config_overrides"], [5, 4, 1, "", "do_rope_scaling"], [5, 4, 1, "", "double_quant"], [5, 4, 1, "", "lora_alpha"], [5, 4, 1, "", "lora_dropout"], [5, 4, 1, "", "lora_model_path"], [5, 4, 1, "", "lora_r"], [5, 4, 1, "", "lora_target_modules"], [5, 4, 1, "", "model_name_or_path"], [5, 4, 1, "", "model_revision"], [5, 4, 1, "", "model_type"], [5, 4, 1, "", "quant_type"], [5, 4, 1, "", "rope_ntk_ratio"], [5, 4, 1, "", "rope_pi_ratio"], [5, 4, 1, "", "save_aggregated_lora"], [5, 4, 1, "", "tokenizer_name"], [5, 4, 1, "", "torch_dtype"], [5, 4, 1, "", "truncate_to_model_max_length"], [5, 4, 1, "", "trust_remote_code"], [5, 4, 1, "", "use_auth_token"], [5, 4, 1, "", "use_fast_tokenizer"], [5, 4, 1, "", "use_flash_attention"], [5, 4, 1, "", "use_int8"], [5, 4, 1, "", "use_lora"], [5, 4, 1, "", "use_qlora"], [5, 4, 1, "", "use_ram_optimized_load"]], "lmflow.args.MultiModalDatasetArguments": [[5, 4, 1, "", "image_aspect_ratio"], [5, 4, 1, "", "image_folder"], [5, 4, 1, "", "is_multimodal"], [5, 4, 1, "", "sep_style"], [5, 4, 1, "", "use_image_start_end"]], "lmflow.args.RaftAlignerArguments": [[5, 4, 1, "", "collection_strategy"], [5, 4, 1, "", "inference_batch_size_per_device"], [5, 4, 1, "", "num_raft_iteration"], [5, 4, 1, "", "output_max_length"], [5, 4, 1, "", "output_min_length"], [5, 4, 1, "", "output_reward_path"], [5, 4, 1, "", "raft_batch_size"], [5, 4, 1, "", "top_reward_percentage"]], "lmflow.args.VisModelArguments": [[5, 4, 1, "", "custom_model"], [5, 4, 1, "", "custom_vision_model"], [5, 4, 1, "", "image_encoder_name_or_path"], [5, 4, 1, "", "llava_loading"], [5, 4, 1, "", "llava_pretrain_model_path"], [5, 4, 1, "", "llm_model_name_or_path"], [5, 4, 1, "", "low_resource"], [5, 4, 1, "", "pretrained_language_projection_path"], [5, 4, 1, "", "prompt_cache_path"], [5, 4, 1, "", "qformer_name_or_path"], [5, 4, 1, "", "save_pretrain_model_path"], [5, 4, 1, "", "use_prompt_cache"], [5, 4, 1, "", "vision_select_layer"], [5, 4, 1, "", "with_qformer"]], "lmflow.datasets": [[7, 2, 1, "", "CustomMultiModalDataset"], [7, 2, 1, "", "Dataset"], [6, 0, 0, "-", "dataset"], [8, 0, 0, "-", "multi_modal_dataset"]], "lmflow.datasets.CustomMultiModalDataset": [[7, 3, 1, "", "__getitem__"], [7, 3, 1, "", "__len__"], [7, 3, 1, "", "register_tokenizer"]], "lmflow.datasets.Dataset": [[7, 3, 1, "", "__len__"], [7, 3, 1, "", "_check_data_format"], [7, 3, 1, "", "create_from_dict"], [7, 3, 1, "", "from_dict"], [7, 3, 1, "", "get_backend"], [7, 3, 1, "", "get_backend_dataset"], [7, 3, 1, "", "get_data_args"], [7, 3, 1, "", "get_fingerprint"], [7, 3, 1, "", "get_type"], [7, 3, 1, "", "map"], [7, 3, 1, "", "to_dict"], [7, 3, 1, "", "to_list"]], "lmflow.datasets.dataset": [[6, 1, 1, "", "DATASET_TYPES"], [6, 2, 1, "", "Dataset"], [6, 1, 1, "", "KEY_INSTANCES"], [6, 1, 1, "", "KEY_TYPE"]], "lmflow.datasets.dataset.Dataset": [[6, 3, 1, "", "__len__"], [6, 3, 1, "", "_check_data_format"], [6, 3, 1, "", "create_from_dict"], [6, 3, 1, "", "from_dict"], [6, 3, 1, "", "get_backend"], [6, 3, 1, "", "get_backend_dataset"], [6, 3, 1, "", "get_data_args"], [6, 3, 1, "", "get_fingerprint"], [6, 3, 1, "", "get_type"], [6, 3, 1, "", "map"], [6, 3, 1, "", "to_dict"], [6, 3, 1, "", "to_list"]], "lmflow.datasets.multi_modal_dataset": [[8, 2, 1, "", "CustomMultiModalDataset"], [8, 2, 1, "", "DataCollatorForSupervisedDataset"], [8, 5, 1, "", "preprocess_llama_from_llava_plain"], [8, 5, 1, "", "preprocess_llama_from_llava_v1"], [8, 5, 1, "", "preprocess_multimodal_llava"], [8, 5, 1, "", "tokenizer_image_token"]], "lmflow.datasets.multi_modal_dataset.CustomMultiModalDataset": [[8, 3, 1, "", "__getitem__"], [8, 3, 1, "", "__len__"], [8, 3, 1, "", "register_tokenizer"]], "lmflow.datasets.multi_modal_dataset.DataCollatorForSupervisedDataset": [[8, 3, 1, "", "__call__"], [8, 4, 1, "", "tokenizer"]], "lmflow.models": [[10, 0, 0, "-", "auto_model"], [11, 0, 0, "-", "base_model"], [12, 0, 0, "-", "decoder_model"], [13, 0, 0, "-", "encoder_decoder_model"], [14, 0, 0, "-", "hf_decoder_model"], [15, 0, 0, "-", "hf_encoder_decoder_model"], [17, 0, 0, "-", "interfaces"], [19, 0, 0, "-", "regression_model"], [20, 0, 0, "-", "text_regression_model"], [21, 0, 0, "-", "vision2seq_model"], [23, 0, 0, "-", "vision_encoder"]], "lmflow.models.auto_model": [[10, 2, 1, "", "AutoModel"]], "lmflow.models.auto_model.AutoModel": [[10, 3, 1, "", "get_model"]], "lmflow.models.base_model": [[11, 2, 1, "", "BaseModel"]], "lmflow.models.decoder_model": [[12, 2, 1, "", "DecoderModel"]], "lmflow.models.encoder_decoder_model": [[13, 2, 1, "", "EncoderDecoderModel"]], "lmflow.models.hf_decoder_model": [[14, 1, 1, "id0", "GPU_SUPPORT_FLASH_ATTENTION"], [14, 2, 1, "", "HFDecoderModel"], [14, 1, 1, "", "MODELS_SUPPORT_FLASH_ATTENTION"], [14, 1, 1, "", "logger"]], "lmflow.models.hf_decoder_model.HFDecoderModel": [[14, 3, 1, "", "decode"], [14, 3, 1, "", "encode"], [14, 3, 1, "", "get_backend_model"], [14, 3, 1, "", "get_max_length"], [14, 3, 1, "", "get_peft_without_qlora"], [14, 3, 1, "", "get_tokenizer"], [14, 3, 1, "", "inference"], [14, 3, 1, "", "merge_lora_weights"], [14, 3, 1, "", "save"], [14, 3, 1, "", "tokenize"]], "lmflow.models.hf_encoder_decoder_model": [[15, 2, 1, "", "HFEncoderDecoderModel"], [15, 1, 1, "", "logger"]], "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel": [[15, 3, 1, "", "decode"], [15, 3, 1, "", "encode"], [15, 3, 1, "", "get_backend_model"], [15, 3, 1, "", "get_max_length"], [15, 3, 1, "", "get_tokenizer"], [15, 3, 1, "", "inference"], [15, 3, 1, "", "merge_lora_weights"], [15, 3, 1, "", "save"], [15, 3, 1, "", "tokenize"]], "lmflow.models.interfaces": [[18, 0, 0, "-", "tunable"]], "lmflow.models.interfaces.tunable": [[18, 2, 1, "", "Tunable"]], "lmflow.models.regression_model": [[19, 2, 1, "", "RegressionModel"]], "lmflow.models.text_regression_model": [[20, 2, 1, "", "TextRegressionModel"]], "lmflow.models.text_regression_model.TextRegressionModel": [[20, 3, 1, "", "inference"], [20, 3, 1, "", "register_inference_function"]], "lmflow.models.vision2seq_model": [[21, 2, 1, "", "CustomAutoVision2SeqModel"]], "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel": [[21, 3, 1, "", "forward"], [21, 3, 1, "", "generate"], [21, 3, 1, "", "get_backend_model"], [21, 3, 1, "", "get_tokenizer"], [21, 3, 1, "", "language_model_from_pretrained"], [21, 3, 1, "", "load_prompt_cache"], [21, 3, 1, "", "processor_image_token_in_minigpt4"], [21, 3, 1, "", "qformer_from_pretrained"], [21, 3, 1, "", "register_prompt_cache"], [21, 3, 1, "", "save_prompt_cache"], [21, 3, 1, "", "vision_feature_select"], [21, 3, 1, "", "vision_model_from_pretrained"]], "lmflow.models.vision_encoder": [[23, 5, 1, "", "build_vision_tower"], [22, 0, 0, "-", "clip_encoder"]], "lmflow.models.vision_encoder.clip_encoder": [[22, 2, 1, "", "CLIPVisionTower"], [22, 5, 1, "", "build_vision_tower"]], "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower": [[22, 6, 1, "", "config"], [22, 6, 1, "", "device"], [22, 6, 1, "", "dtype"], [22, 6, 1, "", "dummy_feature"], [22, 3, 1, "", "encode_images"], [22, 3, 1, "", "feature_select"], [22, 3, 1, "", "forward"], [22, 6, 1, "", "hidden_size"], [22, 3, 1, "", "load_model"], [22, 6, 1, "", "num_patches"], [22, 3, 1, "", "prepare_inputs_labels_for_multimodal"]], "lmflow.pipeline": [[24, 0, 0, "-", "auto_pipeline"], [25, 0, 0, "-", "base_aligner"], [26, 0, 0, "-", "base_pipeline"], [27, 0, 0, "-", "base_tuner"], [28, 0, 0, "-", "evaluator"], [29, 0, 0, "-", "finetuner"], [31, 0, 0, "-", "inferencer"], [32, 0, 0, "-", "raft_aligner"], [33, 0, 0, "-", "utils"]], "lmflow.pipeline.auto_pipeline": [[24, 2, 1, "", "AutoPipeline"], [24, 1, 1, "", "PIPELINE_MAPPING"]], "lmflow.pipeline.auto_pipeline.AutoPipeline": [[24, 3, 1, "", "get_pipeline"]], "lmflow.pipeline.base_aligner": [[25, 2, 1, "", "BaseAligner"]], "lmflow.pipeline.base_aligner.BaseAligner": [[25, 3, 1, "", "_check_if_alignable"], [25, 3, 1, "", "align"]], "lmflow.pipeline.base_pipeline": [[26, 2, 1, "", "BasePipeline"]], "lmflow.pipeline.base_tuner": [[27, 2, 1, "", "BaseTuner"]], "lmflow.pipeline.base_tuner.BaseTuner": [[27, 3, 1, "", "_check_if_tunable"], [27, 3, 1, "", "tune"]], "lmflow.pipeline.evaluator": [[28, 2, 1, "", "Evaluator"]], "lmflow.pipeline.evaluator.Evaluator": [[28, 3, 1, "", "_evaluate_acc_with_accelerator"], [28, 3, 1, "", "_evaluate_acc_with_deepspeed"], [28, 3, 1, "", "_evaluate_nll"], [28, 3, 1, "", "_evaluate_ppl"], [28, 3, 1, "", "_match"], [28, 3, 1, "", "create_dataloader"], [28, 3, 1, "", "evaluate"]], "lmflow.pipeline.finetuner": [[29, 2, 1, "", "Finetuner"], [29, 1, 1, "", "logger"]], "lmflow.pipeline.finetuner.Finetuner": [[29, 3, 1, "", "group_text"], [29, 3, 1, "", "tune"]], "lmflow.pipeline.inferencer": [[31, 2, 1, "", "Inferencer"], [31, 2, 1, "", "SpeculativeInferencer"], [31, 1, 1, "", "logger"], [31, 5, 1, "", "rstrip_partial_utf8"], [31, 1, 1, "", "supported_dataset_type"]], "lmflow.pipeline.inferencer.Inferencer": [[31, 3, 1, "", "create_dataloader"], [31, 3, 1, "", "inference"], [31, 3, 1, "", "stream_inference"]], "lmflow.pipeline.inferencer.SpeculativeInferencer": [[31, 3, 1, "", "autoregressive_sampling"], [31, 3, 1, "", "inference"], [31, 3, 1, "", "predict_next_token"], [31, 3, 1, "", "sample"], [31, 3, 1, "", "score_to_prob"], [31, 3, 1, "", "stream_inference"]], "lmflow.pipeline.raft_aligner": [[32, 2, 1, "", "RaftAligner"], [32, 1, 1, "", "logger"]], "lmflow.pipeline.raft_aligner.RaftAligner": [[32, 3, 1, "", "_clean_text"], [32, 3, 1, "", "_discard_sample"], [32, 3, 1, "", "_get_batch_dataset_local"], [32, 3, 1, "", "_get_batch_dataset_top"], [32, 3, 1, "", "_initialize_trainer"], [32, 3, 1, "", "_load_dataset"], [32, 3, 1, "", "_load_input_dataset"], [32, 3, 1, "", "align"]], "lmflow.pipeline.utils": [[34, 0, 0, "-", "peft_trainer"], [35, 0, 0, "-", "raft_trainer"]], "lmflow.pipeline.utils.peft_trainer": [[34, 2, 1, "", "PeftSavingCallback"], [34, 2, 1, "", "PeftTrainer"]], "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback": [[34, 3, 1, "", "_save"], [34, 3, 1, "", "on_epoch_end"], [34, 3, 1, "", "on_save"], [34, 3, 1, "", "on_train_end"]], "lmflow.pipeline.utils.peft_trainer.PeftTrainer": [[34, 3, 1, "", "_save_checkpoint"]], "lmflow.pipeline.utils.raft_trainer": [[35, 1, 1, "", "DEFAULT_CALLBACKS"], [35, 1, 1, "id0", "DEFAULT_PROGRESS_CALLBACK"], [35, 1, 1, "", "IS_SAGEMAKER_MP_POST_1_10"], [35, 1, 1, "", "OPTIMIZER_NAME"], [35, 2, 1, "", "RaftTrainer"], [35, 1, 1, "", "SCALER_NAME"], [35, 1, 1, "", "SCHEDULER_NAME"], [35, 1, 1, "", "TRAINER_STATE_NAME"], [35, 1, 1, "", "TRAINING_ARGS_NAME"], [35, 1, 1, "", "_is_native_cpu_amp_available"], [35, 1, 1, "", "is_torch_greater_or_equal_than_1_10"], [35, 1, 1, "", "is_torch_less_than_1_11"], [35, 1, 1, "", "logger"], [35, 1, 1, "", "skip_first_batches"]], "lmflow.pipeline.utils.raft_trainer.RaftTrainer": [[35, 3, 1, "", "_add_sm_patterns_to_gitignore"], [35, 3, 1, "", "_gather_and_numpify"], [35, 3, 1, "", "_get_collator_with_removed_columns"], [35, 3, 1, "", "_get_eval_sampler"], [35, 3, 1, "", "_get_output_dir"], [35, 3, 1, "", "_get_train_sampler"], [35, 3, 1, "", "_hp_search_setup"], [35, 3, 1, "", "_inner_training_loop"], [35, 3, 1, "", "_issue_warnings_after_load"], [35, 3, 1, "", "_load_best_model"], [35, 3, 1, "", "_load_from_checkpoint"], [35, 3, 1, "", "_load_optimizer_and_scheduler"], [35, 3, 1, "", "_load_rng_state"], [35, 3, 1, "", "_maybe_log_save_evaluate"], [35, 3, 1, "", "_move_model_to_device"], [35, 3, 1, "", "_nested_gather"], [35, 3, 1, "", "_one_train"], [35, 3, 1, "", "_pad_across_processes"], [35, 3, 1, "", "_prepare_input"], [35, 3, 1, "", "_prepare_inputs"], [35, 3, 1, "", "_push_from_checkpoint"], [35, 3, 1, "", "_remove_unused_columns"], [35, 3, 1, "", "_report_to_hp_search"], [35, 3, 1, "", "_rotate_checkpoints"], [35, 3, 1, "", "_save"], [35, 3, 1, "", "_save_checkpoint"], [35, 3, 1, "", "_save_tpu"], [35, 3, 1, "", "_set_signature_columns_if_needed"], [35, 3, 1, "", "_sorted_checkpoints"], [35, 3, 1, "", "_tune_save_checkpoint"], [35, 3, 1, "", "_wrap_model"], [35, 3, 1, "", "add_callback"], [35, 3, 1, "", "autocast_smart_context_manager"], [35, 3, 1, "", "call_model_init"], [35, 3, 1, "", "compute_loss"], [35, 3, 1, "", "compute_loss_context_manager"], [35, 3, 1, "", "create_model_card"], [35, 3, 1, "", "create_optimizer"], [35, 3, 1, "", "create_optimizer_and_scheduler"], [35, 3, 1, "", "create_scheduler"], [35, 3, 1, "", "evaluate"], [35, 3, 1, "", "evaluation_loop"], [35, 3, 1, "", "floating_point_ops"], [35, 3, 1, "", "get_eval_dataloader"], [35, 3, 1, "", "get_optimizer_cls_and_kwargs"], [35, 3, 1, "", "get_test_dataloader"], [35, 3, 1, "", "get_train_dataloader"], [35, 3, 1, "", "hyperparameter_search"], [35, 3, 1, "", "init_git_repo"], [35, 3, 1, "", "ipex_optimize_model"], [35, 3, 1, "", "is_local_process_zero"], [35, 3, 1, "", "is_world_process_zero"], [35, 3, 1, "", "log"], [35, 3, 1, "", "num_examples"], [35, 3, 1, "", "pop_callback"], [35, 3, 1, "", "predict"], [35, 3, 1, "", "prediction_loop"], [35, 3, 1, "", "prediction_step"], [35, 3, 1, "", "push_to_hub"], [35, 3, 1, "", "remove_callback"], [35, 3, 1, "", "save_model"], [35, 3, 1, "", "store_flos"], [35, 3, 1, "", "torch_jit_model_eval"], [35, 3, 1, "", "train"], [35, 3, 1, "", "training_step"]], "lmflow.utils": [[36, 0, 0, "-", "constants"], [37, 0, 0, "-", "data_utils"], [41, 0, 0, "-", "flash_attention"], [45, 0, 0, "-", "llava_conversation_lib"], [46, 0, 0, "-", "multimodal"], [47, 0, 0, "-", "position_interpolation"]], "lmflow.utils.constants": [[36, 1, 1, "", "CONTROLLER_HEART_BEAT_EXPIRATION"], [36, 1, 1, "", "DATASET_DESCRIPTION_MAP"], [36, 1, 1, "", "DEFAULT_IMAGE_PATCH_TOKEN"], [36, 1, 1, "", "DEFAULT_IMAGE_TOKEN"], [36, 1, 1, "", "DEFAULT_IM_END_TOKEN"], [36, 1, 1, "", "DEFAULT_IM_START_TOKEN"], [36, 1, 1, "", "FLOAT_ONLY_DATASET_DESCRIPTION"], [36, 1, 1, "", "IGNORE_INDEX"], [36, 1, 1, "", "IMAGE_TOKEN_INDEX"], [36, 1, 1, "", "INSTANCE_FIELDS_MAP"], [36, 1, 1, "", "LOGDIR"], [36, 1, 1, "", "TEXT2TEXT_DATASET_DESCRIPTION"], [36, 1, 1, "", "TEXT2TEXT_DATASET_DETAILS"], [36, 1, 1, "", "TEXT2TEXT_DATASET_LONG_DESCRITION"], [36, 1, 1, "", "TEXT_ONLY_DATASET_DESCRIPTION"], [36, 1, 1, "", "TEXT_ONLY_DATASET_DETAILS"], [36, 1, 1, "", "TEXT_ONLY_DATASET_LONG_DESCRITION"], [36, 1, 1, "", "WORKER_HEART_BEAT_INTERVAL"]], "lmflow.utils.data_utils": [[37, 5, 1, "", "answer_extraction"], [37, 5, 1, "", "batchlize"], [37, 5, 1, "", "load_data"], [37, 5, 1, "", "process_image_flag"], [37, 5, 1, "", "set_random_seed"]], "lmflow.utils.flash_attention": [[38, 0, 0, "-", "bloom_flash_attention"], [39, 0, 0, "-", "gpt2_flash_attention"], [40, 0, 0, "-", "gpt_neo_flash_attention"], [42, 0, 0, "-", "llama_flash_attention"], [43, 0, 0, "-", "triton_flash_attention"]], "lmflow.utils.flash_attention.bloom_flash_attention": [[38, 5, 1, "", "_prepare_attn_mask"], [38, 5, 1, "", "forward"], [38, 5, 1, "", "replace_bloom_attn_with_flash_attn"]], "lmflow.utils.flash_attention.gpt2_flash_attention": [[39, 5, 1, "", "_prepare_decoder_attention_mask"], [39, 5, 1, "", "forward"], [39, 5, 1, "", "replace_gpt2_attn_with_flash_attn"]], "lmflow.utils.flash_attention.gpt_neo_flash_attention": [[40, 5, 1, "", "_attn"], [40, 5, 1, "", "forward"], [40, 5, 1, "", "replace_gpt_neo_attn_with_flash_attn"]], "lmflow.utils.flash_attention.llama_flash_attention": [[42, 5, 1, "", "_prepare_decoder_attention_mask"], [42, 5, 1, "", "forward"], [42, 5, 1, "", "replace_llama_attn_with_flash_attn"]], "lmflow.utils.flash_attention.triton_flash_attention": [[43, 2, 1, "", "FlashAttnFunc"], [43, 2, 1, "", "FlashAttnKVPackedFunc"], [43, 2, 1, "", "FlashAttnQKVPackedFunc"], [43, 5, 1, "", "_bwd_kernel"], [43, 5, 1, "", "_bwd_kernel_one_col_block"], [43, 5, 1, "", "_bwd_preprocess_do_o_dot"], [43, 5, 1, "", "_bwd_store_dk_dv"], [43, 5, 1, "", "_flash_attn_backward"], [43, 5, 1, "", "_flash_attn_forward"], [43, 5, 1, "", "_fwd_kernel"], [43, 1, 1, "", "flash_attn_func"], [43, 1, 1, "", "flash_attn_kvpacked_func"], [43, 1, 1, "", "flash_attn_qkvpacked_func"], [43, 5, 1, "", "init_to_zero"]], "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnFunc": [[43, 3, 1, "", "backward"], [43, 3, 1, "", "forward"]], "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnKVPackedFunc": [[43, 3, 1, "", "backward"], [43, 3, 1, "", "forward"]], "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnQKVPackedFunc": [[43, 3, 1, "", "backward"], [43, 3, 1, "", "forward"]], "lmflow.utils.llava_conversation_lib": [[45, 2, 1, "", "Conversation"], [45, 2, 1, "", "SeparatorStyle"], [45, 1, 1, "", "conv_llama_2"], [45, 1, 1, "", "conv_llava_llama_2"], [45, 1, 1, "", "conv_llava_plain"], [45, 1, 1, "", "conv_llava_v0"], [45, 1, 1, "", "conv_llava_v0_mmtag"], [45, 1, 1, "", "conv_llava_v1"], [45, 1, 1, "", "conv_llava_v1_mmtag"], [45, 1, 1, "", "conv_mpt"], [45, 1, 1, "", "conv_templates"], [45, 1, 1, "", "conv_vicuna_v0"], [45, 1, 1, "", "conv_vicuna_v1"], [45, 1, 1, "", "default_conversation"]], "lmflow.utils.llava_conversation_lib.Conversation": [[45, 3, 1, "", "append_message"], [45, 3, 1, "", "copy"], [45, 3, 1, "", "dict"], [45, 3, 1, "", "get_images"], [45, 3, 1, "", "get_prompt"], [45, 4, 1, "", "messages"], [45, 4, 1, "", "offset"], [45, 4, 1, "", "roles"], [45, 4, 1, "", "sep"], [45, 4, 1, "", "sep2"], [45, 4, 1, "", "sep_style"], [45, 4, 1, "", "skip_next"], [45, 4, 1, "", "system"], [45, 3, 1, "", "to_gradio_chatbot"], [45, 4, 1, "", "version"]], "lmflow.utils.llava_conversation_lib.SeparatorStyle": [[45, 4, 1, "", "LLAMA_2"], [45, 4, 1, "", "MPT"], [45, 4, 1, "", "PLAIN"], [45, 4, 1, "", "SINGLE"], [45, 4, 1, "", "TWO"]], "lmflow.utils.multimodal": [[46, 5, 1, "", "adapt_llava_model_to_lmflow_type"], [46, 5, 1, "", "load_llava_pretrain_model"], [46, 5, 1, "", "update_custom_config"]], "lmflow.utils.position_interpolation": [[48, 0, 0, "-", "llama_rope_scaled_monkey_patch"]], "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch": [[48, 2, 1, "", "CondenseRotaryEmbedding"], [48, 5, 1, "", "replace_llama_with_condense"]], "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.CondenseRotaryEmbedding": [[48, 3, 1, "", "forward"]], "lmflow.version": [[49, 1, 1, "", "__version__"]]}, "objtypes": {"0": "py:module", "1": "py:data", "2": "py:class", "3": "py:method", "4": "py:attribute", "5": "py:function", "6": "py:property"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "data", "Python data"], "2": ["py", "class", "Python class"], "3": ["py", "method", "Python method"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"], "6": ["py", "property", "Python property"]}, "titleterms": {"contributor": 0, "changelog": 1, "version": [1, 49], "0": 1, "1": [1, 53, 57, 58], "mar": 1, "28": 1, "2023": [1, 51], "about": 2, "lmflow": [3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 59], "arg": [3, 5], "api": 4, "refer": [4, 50], "modul": [5, 6, 8, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 48, 49], "content": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 48, 49, 59], "class": [5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 43, 45, 48], "attribut": [5, 6, 14, 15, 24, 29, 31, 32, 35, 43, 45], "dataset": [6, 7, 8, 52, 53, 57], "submodul": [7, 9, 16, 17, 23, 30, 33, 41, 44, 47], "packag": [7, 9, 23], "multi_modal_dataset": 8, "function": [8, 22, 23, 31, 37, 38, 39, 40, 42, 43, 46, 48], "subpackag": [9, 16, 30, 44], "model": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 57, 58], "auto_model": 10, "base_model": 11, "decoder_model": 12, "encoder_decoder_model": 13, "hf_decoder_model": 14, "hf_encoder_decoder_model": 15, "interfac": [17, 18], "tunabl": 18, "regression_model": 19, "text_regression_model": 20, "vision2seq_model": 21, "vision_encod": [22, 23], "clip_encod": 22, "pipelin": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "auto_pipelin": 24, "base_align": 25, "base_pipelin": 26, "base_tun": 27, "evalu": [28, 50, 53, 55], "finetun": [29, 55, 56, 57, 58], "inferenc": 31, "raft_align": 32, "util": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48], "peft_train": 34, "raft_train": 35, "constant": 36, "data_util": 37, "flash_attent": [38, 39, 40, 41, 42, 43], "bloom_flash_attent": 38, "gpt2_flash_attent": 39, "gpt_neo_flash_attent": 40, "llama_flash_attent": 42, "triton_flash_attent": 43, "llava_conversation_lib": 45, "multimod": 46, "position_interpol": [47, 48], "llama_rope_scaled_monkey_patch": 48, "benchmark": [50, 53], "an": 50, "automat": 50, "framework": 50, "open": 50, "sourc": 50, "llm": 50, "introduct": [50, 57, 58, 59], "metric": 50, "chat": 50, "perform": 50, "commonsens": 50, "instruct": [50, 59], "follow": 50, "conclus": 50, "blog": 51, "format": 52, "gener": 52, "support": [52, 59], "detail": 52, "textonli": 52, "text2text": 52, "guid": 53, "nll": 53, "task": [53, 59], "set": 53, "setup": 53, "creat": 53, "your": 53, "file": 53, "registr": 53, "2": [53, 57, 58], "lm": 53, "checkpoint": [54, 59], "llama": 54, "exampl": [55, 57, 58], "data": 55, "prepar": 55, "infer": 55, "raft": 57, "descript": 57, "reward": [57, 58], "supervis": [57, 58], "sft": [57, 58], "3": 57, "lora": 57, "merg": 57, "get": 57, "align": 57, "algorithm": 57, "overview": 57, "hyper": 57, "paramet": 57, "end": 57, "note": 57, "step": 58, "featur": 59, "tune": 59, "instal": 59, "vision": 59, "citat": 59, "disclaim": 59, "indic": 59, "tabl": 59}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Contributors": [[0, "contributors"]], "Changelog": [[1, "changelog"]], "Version 0.0.1 (Mar 28, 2023)": [[1, "version-0-0-1-mar-28-2023"]], "About": [[2, "about"]], "lmflow.args": [[3, "module-lmflow.args"], [5, "module-lmflow.args"]], "API Reference": [[4, "api-reference"]], "Module Contents": [[5, "module-contents"], [6, "module-contents"], [8, "module-contents"], [10, "module-contents"], [11, "module-contents"], [12, "module-contents"], [13, "module-contents"], [14, "module-contents"], [15, "module-contents"], [18, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [24, "module-contents"], [25, "module-contents"], [26, "module-contents"], [27, "module-contents"], [28, "module-contents"], [29, "module-contents"], [31, "module-contents"], [32, "module-contents"], [34, "module-contents"], [35, "module-contents"], [36, "module-contents"], [37, "module-contents"], [38, "module-contents"], [39, "module-contents"], [40, "module-contents"], [42, "module-contents"], [43, "module-contents"], [45, "module-contents"], [46, "module-contents"], [48, "module-contents"], [49, "module-contents"]], "Classes": [[5, "classes"], [6, "classes"], [7, "classes"], [8, "classes"], [10, "classes"], [11, "classes"], [12, "classes"], [13, "classes"], [14, "classes"], [15, "classes"], [18, "classes"], [19, "classes"], [20, "classes"], [21, "classes"], [22, "classes"], [24, "classes"], [25, "classes"], [26, "classes"], [27, "classes"], [28, "classes"], [29, "classes"], [31, "classes"], [32, "classes"], [34, "classes"], [35, "classes"], [43, "classes"], [45, "classes"], [48, "classes"]], "Attributes": [[5, "attributes"], [6, "attributes"], [14, "attributes"], [15, "attributes"], [24, "attributes"], [29, "attributes"], [31, "attributes"], [32, "attributes"], [35, "attributes"], [43, "attributes"], [45, "attributes"]], "lmflow.datasets.dataset": [[6, "module-lmflow.datasets.dataset"]], "lmflow.datasets": [[7, "module-lmflow.datasets"]], "Submodules": [[7, "submodules"], [9, "submodules"], [16, "submodules"], [17, "submodules"], [23, "submodules"], [30, "submodules"], [33, "submodules"], [41, "submodules"], [44, "submodules"], [47, "submodules"]], "Package Contents": [[7, "package-contents"], [9, "package-contents"], [23, "package-contents"]], "lmflow.datasets.multi_modal_dataset": [[8, "module-lmflow.datasets.multi_modal_dataset"]], "Functions": [[8, "functions"], [22, "functions"], [23, "functions"], [31, "functions"], [37, "functions"], [38, "functions"], [39, "functions"], [40, "functions"], [42, "functions"], [43, "functions"], [46, "functions"], [48, "functions"]], "lmflow": [[9, "module-lmflow"]], "Subpackages": [[9, "subpackages"], [16, "subpackages"], [30, "subpackages"], [44, "subpackages"]], "lmflow.models.auto_model": [[10, "module-lmflow.models.auto_model"]], "lmflow.models.base_model": [[11, "module-lmflow.models.base_model"]], "lmflow.models.decoder_model": [[12, "module-lmflow.models.decoder_model"]], "lmflow.models.encoder_decoder_model": [[13, "module-lmflow.models.encoder_decoder_model"]], "lmflow.models.hf_decoder_model": [[14, "module-lmflow.models.hf_decoder_model"]], "lmflow.models.hf_encoder_decoder_model": [[15, "module-lmflow.models.hf_encoder_decoder_model"]], "lmflow.models": [[16, "module-lmflow.models"]], "lmflow.models.interfaces": [[17, "module-lmflow.models.interfaces"]], "lmflow.models.interfaces.tunable": [[18, "module-lmflow.models.interfaces.tunable"]], "lmflow.models.regression_model": [[19, "module-lmflow.models.regression_model"]], "lmflow.models.text_regression_model": [[20, "module-lmflow.models.text_regression_model"]], "lmflow.models.vision2seq_model": [[21, "module-lmflow.models.vision2seq_model"]], "lmflow.models.vision_encoder.clip_encoder": [[22, "module-lmflow.models.vision_encoder.clip_encoder"]], "lmflow.models.vision_encoder": [[23, "module-lmflow.models.vision_encoder"]], "lmflow.pipeline.auto_pipeline": [[24, "module-lmflow.pipeline.auto_pipeline"]], "lmflow.pipeline.base_aligner": [[25, "module-lmflow.pipeline.base_aligner"]], "lmflow.pipeline.base_pipeline": [[26, "module-lmflow.pipeline.base_pipeline"]], "lmflow.pipeline.base_tuner": [[27, "module-lmflow.pipeline.base_tuner"]], "lmflow.pipeline.evaluator": [[28, "module-lmflow.pipeline.evaluator"]], "lmflow.pipeline.finetuner": [[29, "module-lmflow.pipeline.finetuner"]], "lmflow.pipeline": [[30, "module-lmflow.pipeline"]], "lmflow.pipeline.inferencer": [[31, "module-lmflow.pipeline.inferencer"]], "lmflow.pipeline.raft_aligner": [[32, "module-lmflow.pipeline.raft_aligner"]], "lmflow.pipeline.utils": [[33, "module-lmflow.pipeline.utils"]], "lmflow.pipeline.utils.peft_trainer": [[34, "module-lmflow.pipeline.utils.peft_trainer"]], "lmflow.pipeline.utils.raft_trainer": [[35, "module-lmflow.pipeline.utils.raft_trainer"]], "lmflow.utils.constants": [[36, "module-lmflow.utils.constants"]], "lmflow.utils.data_utils": [[37, "module-lmflow.utils.data_utils"]], "lmflow.utils.flash_attention.bloom_flash_attention": [[38, "module-lmflow.utils.flash_attention.bloom_flash_attention"]], "lmflow.utils.flash_attention.gpt2_flash_attention": [[39, "module-lmflow.utils.flash_attention.gpt2_flash_attention"]], "lmflow.utils.flash_attention.gpt_neo_flash_attention": [[40, "module-lmflow.utils.flash_attention.gpt_neo_flash_attention"]], "lmflow.utils.flash_attention": [[41, "module-lmflow.utils.flash_attention"]], "lmflow.utils.flash_attention.llama_flash_attention": [[42, "module-lmflow.utils.flash_attention.llama_flash_attention"]], "lmflow.utils.flash_attention.triton_flash_attention": [[43, "module-lmflow.utils.flash_attention.triton_flash_attention"]], "lmflow.utils": [[44, "module-lmflow.utils"]], "lmflow.utils.llava_conversation_lib": [[45, "module-lmflow.utils.llava_conversation_lib"]], "lmflow.utils.multimodal": [[46, "module-lmflow.utils.multimodal"]], "lmflow.utils.position_interpolation": [[47, "module-lmflow.utils.position_interpolation"]], "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch": [[48, "module-lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch"]], "lmflow.version": [[49, "module-lmflow.version"]], "LMFlow Benchmark: An Automatic Evaluation Framework for Open-Source LLMs": [[50, "lmflow-benchmark-an-automatic-evaluation-framework-for-open-source-llms"]], "Introduction": [[50, "introduction"], [58, "introduction"], [59, "introduction"]], "Metric": [[50, "metric"]], "Chat Performance": [[50, "chat-performance"]], "CommonSense Performance": [[50, "commonsense-performance"]], "Instruction Following": [[50, "instruction-following"]], "Conclusion": [[50, "conclusion"]], "References": [[50, "references"]], "Blogs": [[51, "blogs"]], "2023": [[51, "id1"]], "Dataset": [[52, "dataset"]], "Dataset Format in General": [[52, "dataset-format-in-general"]], "Supported Dataset and Detailed Formats": [[52, "supported-dataset-and-detailed-formats"]], "TextOnly": [[52, "textonly"]], "Text2Text": [[52, "text2text"]], "LMFlow Benchmark Guide": [[53, "lmflow-benchmark-guide"]], "1. NLL Task Setting": [[53, "nll-task-setting"]], "Setup": [[53, "setup"]], "Create Your Task Dataset File": [[53, "create-your-task-dataset-file"]], "Task Registration": [[53, "task-registration"]], "2. LM-Evaluation Task Setting": [[53, "lm-evaluation-task-setting"]], "Checkpoints": [[54, "checkpoints"], [59, "checkpoints"]], "LLaMA Checkpoint": [[54, "llama-checkpoint"]], "Examples": [[55, "examples"], [58, "examples"]], "Data preparation": [[55, "data-preparation"]], "Finetuning": [[55, "finetuning"]], "Inference": [[55, "inference"]], "Evaluation": [[55, "evaluation"]], "Finetune": [[56, "finetune"]], "RAFT": [[57, "raft"]], "1 Introduction": [[57, "introduction"]], "1.1 Dataset description": [[57, "dataset-description"]], "2 Reward Modeling": [[57, "reward-modeling"]], "2.1 Supervised Finetuning (SFT)": [[57, "supervised-finetuning-sft"]], "2.2 Reward Modeling": [[57, "id1"]], "2.3 LoRA Merge and Get Reward Model": [[57, "lora-merge-and-get-reward-model"]], "3 RAFT Alignment": [[57, "raft-alignment"]], "3.1 Algorithms Overview": [[57, "algorithms-overview"]], "3.2 Hyper-parameters": [[57, "hyper-parameters"]], "3.3 Examples": [[57, "examples"]], "3.3.1 SFT": [[57, "sft"]], "3.3.2 RAFT Alignment": [[57, "id2"]], "3.3.3 End Note": [[57, "end-note"]], "Reward Modeling": [[58, "reward-modeling"]], "Step 1 Supervised Finetuning (SFT)": [[58, "step-1-supervised-finetuning-sft"]], "Step 2 Reward Modeling": [[58, "step-2-reward-modeling"]], "LMFlow": [[59, "lmflow"]], "Features": [[59, "features"]], "Task Tuning": [[59, "task-tuning"]], "Instruction Tuning": [[59, "instruction-tuning"]], "Installation": [[59, "installation"]], "Content": [[59, "content"]], "Vision": [[59, "vision"]], "Citation": [[59, "citation"]], "Disclaimer": [[59, "disclaimer"]], "Support": [[59, "support"]], "Indices and tables": [[59, "indices-and-tables"]]}, "indexentries": {"lmflow.args": [[3, "module-lmflow.args"], [5, "module-lmflow.args"]], "module": [[3, "module-lmflow.args"], [5, "module-lmflow.args"], [6, "module-lmflow.datasets.dataset"], [7, "module-lmflow.datasets"], [8, "module-lmflow.datasets.multi_modal_dataset"], [9, "module-lmflow"], [10, "module-lmflow.models.auto_model"], [11, "module-lmflow.models.base_model"], [12, "module-lmflow.models.decoder_model"], [13, "module-lmflow.models.encoder_decoder_model"], [14, "module-lmflow.models.hf_decoder_model"], [15, "module-lmflow.models.hf_encoder_decoder_model"], [16, "module-lmflow.models"], [17, "module-lmflow.models.interfaces"], [18, "module-lmflow.models.interfaces.tunable"], [19, "module-lmflow.models.regression_model"], [20, "module-lmflow.models.text_regression_model"], [21, "module-lmflow.models.vision2seq_model"], [22, "module-lmflow.models.vision_encoder.clip_encoder"], [23, "module-lmflow.models.vision_encoder"], [24, "module-lmflow.pipeline.auto_pipeline"], [25, "module-lmflow.pipeline.base_aligner"], [26, "module-lmflow.pipeline.base_pipeline"], [27, "module-lmflow.pipeline.base_tuner"], [28, "module-lmflow.pipeline.evaluator"], [29, "module-lmflow.pipeline.finetuner"], [30, "module-lmflow.pipeline"], [31, "module-lmflow.pipeline.inferencer"], [32, "module-lmflow.pipeline.raft_aligner"], [33, "module-lmflow.pipeline.utils"], [34, "module-lmflow.pipeline.utils.peft_trainer"], [35, "module-lmflow.pipeline.utils.raft_trainer"], [36, "module-lmflow.utils.constants"], [37, "module-lmflow.utils.data_utils"], [38, "module-lmflow.utils.flash_attention.bloom_flash_attention"], [39, "module-lmflow.utils.flash_attention.gpt2_flash_attention"], [40, "module-lmflow.utils.flash_attention.gpt_neo_flash_attention"], [41, "module-lmflow.utils.flash_attention"], [42, "module-lmflow.utils.flash_attention.llama_flash_attention"], [43, "module-lmflow.utils.flash_attention.triton_flash_attention"], [44, "module-lmflow.utils"], [45, "module-lmflow.utils.llava_conversation_lib"], [46, "module-lmflow.utils.multimodal"], [47, "module-lmflow.utils.position_interpolation"], [48, "module-lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch"], [49, "module-lmflow.version"]], "autoarguments (class in lmflow.args)": [[5, "lmflow.args.AutoArguments"]], "benchmarkingarguments (class in lmflow.args)": [[5, "lmflow.args.BenchmarkingArguments"]], "datasetarguments (class in lmflow.args)": [[5, "lmflow.args.DatasetArguments"]], "evaluatorarguments (class in lmflow.args)": [[5, "lmflow.args.EvaluatorArguments"]], "finetunerarguments (class in lmflow.args)": [[5, "lmflow.args.FinetunerArguments"]], "inferencerarguments (class in lmflow.args)": [[5, "lmflow.args.InferencerArguments"]], "model_config_classes (in module lmflow.args)": [[5, "lmflow.args.MODEL_CONFIG_CLASSES"]], "model_types (in module lmflow.args)": [[5, "lmflow.args.MODEL_TYPES"]], "modelarguments (class in lmflow.args)": [[5, "lmflow.args.ModelArguments"]], "multimodaldatasetarguments (class in lmflow.args)": [[5, "lmflow.args.MultiModalDatasetArguments"]], "pipeline_argument_mapping (in module lmflow.args)": [[5, "lmflow.args.PIPELINE_ARGUMENT_MAPPING"]], "raftalignerarguments (class in lmflow.args)": [[5, "lmflow.args.RaftAlignerArguments"]], "vismodelarguments (class in lmflow.args)": [[5, "lmflow.args.VisModelArguments"]], "__post_init__() (lmflow.args.datasetarguments method)": [[5, "lmflow.args.DatasetArguments.__post_init__"]], "__post_init__() (lmflow.args.modelarguments method)": [[5, "lmflow.args.ModelArguments.__post_init__"]], "answer_type (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.answer_type"]], "arch_type (lmflow.args.modelarguments attribute)": [[5, "id0"], [5, "lmflow.args.ModelArguments.arch_type"]], "bits (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.bits"]], "block_size (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.block_size"]], "cache_dir (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.cache_dir"]], "collection_strategy (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.collection_strategy"]], "config_name (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.config_name"]], "config_overrides (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.config_overrides"]], "custom_model (lmflow.args.vismodelarguments attribute)": [[5, "lmflow.args.VisModelArguments.custom_model"]], "custom_vision_model (lmflow.args.vismodelarguments attribute)": [[5, "lmflow.args.VisModelArguments.custom_vision_model"]], "customized_cache_dir (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.customized_cache_dir"]], "dataset_config_name (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_config_name"]], "dataset_name (lmflow.args.benchmarkingarguments attribute)": [[5, "lmflow.args.BenchmarkingArguments.dataset_name"]], "dataset_name (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_name"]], "dataset_path (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_path"]], "deepspeed (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.deepspeed"]], "deepspeed (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.deepspeed"]], "device (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.device"]], "disable_group_texts (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.disable_group_texts"]], "do_rope_scaling (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.do_rope_scaling"]], "do_sample (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.do_sample"]], "double_quant (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.double_quant"]], "eval_dataset_path (lmflow.args.finetunerarguments attribute)": [[5, "lmflow.args.FinetunerArguments.eval_dataset_path"]], "evaluate_block_size (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.evaluate_block_size"]], "finetune_part (lmflow.args.finetunerarguments attribute)": [[5, "lmflow.args.FinetunerArguments.finetune_part"]], "get_pipeline_args_class() (lmflow.args.autoarguments method)": [[5, "lmflow.args.AutoArguments.get_pipeline_args_class"]], "group_texts_batch_size (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.group_texts_batch_size"]], "image_aspect_ratio (lmflow.args.multimodaldatasetarguments attribute)": [[5, "lmflow.args.MultiModalDatasetArguments.image_aspect_ratio"]], "image_encoder_name_or_path (lmflow.args.vismodelarguments attribute)": [[5, "lmflow.args.VisModelArguments.image_encoder_name_or_path"]], "image_folder (lmflow.args.multimodaldatasetarguments attribute)": [[5, "lmflow.args.MultiModalDatasetArguments.image_folder"]], "inference_batch_size_per_device (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.inference_batch_size_per_device"]], "inference_batch_size_per_device (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.inference_batch_size_per_device"]], "is_custom_dataset (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.is_custom_dataset"]], "is_multimodal (lmflow.args.multimodaldatasetarguments attribute)": [[5, "lmflow.args.MultiModalDatasetArguments.is_multimodal"]], "keep_linebreaks (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.keep_linebreaks"]], "llava_loading (lmflow.args.vismodelarguments attribute)": [[5, "lmflow.args.VisModelArguments.llava_loading"]], "llava_pretrain_model_path (lmflow.args.vismodelarguments attribute)": [[5, "lmflow.args.VisModelArguments.llava_pretrain_model_path"]], "llm_model_name_or_path (lmflow.args.vismodelarguments attribute)": [[5, "lmflow.args.VisModelArguments.llm_model_name_or_path"]], "lm_evaluation_metric (lmflow.args.benchmarkingarguments attribute)": [[5, "lmflow.args.BenchmarkingArguments.lm_evaluation_metric"]], "local_rank (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.local_rank"]], "local_rank (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.local_rank"]], "lora_alpha (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_alpha"]], "lora_dropout (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_dropout"]], "lora_model_path (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_model_path"]], "lora_r (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_r"]], "lora_target_modules (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_target_modules"]], "low_resource (lmflow.args.vismodelarguments attribute)": [[5, "lmflow.args.VisModelArguments.low_resource"]], "max_eval_samples (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.max_eval_samples"]], "max_new_tokens (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.max_new_tokens"]], "max_new_tokens (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.max_new_tokens"]], "max_train_samples (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.max_train_samples"]], "metric (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.metric"]], "mixed_precision (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.mixed_precision"]], "mixed_precision (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.mixed_precision"]], "model_name_or_path (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_name_or_path"]], "model_revision (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_revision"]], "model_type (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_type"]], "num_raft_iteration (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.num_raft_iteration"]], "output_dir (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.output_dir"]], "output_max_length (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.output_max_length"]], "output_min_length (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.output_min_length"]], "output_reward_path (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.output_reward_path"]], "overwrite_cache (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.overwrite_cache"]], "preprocessing_num_workers (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.preprocessing_num_workers"]], "pretrained_language_projection_path (lmflow.args.vismodelarguments attribute)": [[5, "lmflow.args.VisModelArguments.pretrained_language_projection_path"]], "prompt_cache_path (lmflow.args.vismodelarguments attribute)": [[5, "lmflow.args.VisModelArguments.prompt_cache_path"]], "prompt_structure (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.prompt_structure"]], "qformer_name_or_path (lmflow.args.vismodelarguments attribute)": [[5, "lmflow.args.VisModelArguments.qformer_name_or_path"]], "quant_type (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.quant_type"]], "raft_batch_size (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.raft_batch_size"]], "random_seed (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.random_seed"]], "random_seed (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.random_seed"]], "random_shuffle (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.random_shuffle"]], "remove_unused_columns (lmflow.args.finetunerarguments attribute)": [[5, "lmflow.args.FinetunerArguments.remove_unused_columns"]], "repetition_penalty (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.repetition_penalty"]], "repetition_penalty (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.repetition_penalty"]], "rope_ntk_ratio (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.rope_ntk_ratio"]], "rope_pi_ratio (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.rope_pi_ratio"]], "save_aggregated_lora (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.save_aggregated_lora"]], "save_language_projection (lmflow.args.finetunerarguments attribute)": [[5, "lmflow.args.FinetunerArguments.save_language_projection"]], "save_pretrain_model_path (lmflow.args.vismodelarguments attribute)": [[5, "lmflow.args.VisModelArguments.save_pretrain_model_path"]], "sep_style (lmflow.args.multimodaldatasetarguments attribute)": [[5, "lmflow.args.MultiModalDatasetArguments.sep_style"]], "streaming (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.streaming"]], "temperature (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.temperature"]], "temperature (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.temperature"]], "test_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.test_file"]], "tokenizer_name (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.tokenizer_name"]], "top_reward_percentage (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.top_reward_percentage"]], "torch_dtype (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.torch_dtype"]], "train_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.train_file"]], "truncate_to_model_max_length (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.truncate_to_model_max_length"]], "trust_remote_code (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.trust_remote_code"]], "use_accelerator_for_evaluator (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.use_accelerator_for_evaluator"]], "use_auth_token (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_auth_token"]], "use_fast_tokenizer (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_fast_tokenizer"]], "use_flash_attention (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_flash_attention"]], "use_image_start_end (lmflow.args.multimodaldatasetarguments attribute)": [[5, "lmflow.args.MultiModalDatasetArguments.use_image_start_end"]], "use_int8 (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_int8"]], "use_lora (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_lora"]], "use_prompt_cache (lmflow.args.vismodelarguments attribute)": [[5, "lmflow.args.VisModelArguments.use_prompt_cache"]], "use_qlora (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_qlora"]], "use_ram_optimized_load (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_ram_optimized_load"]], "use_wandb (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.use_wandb"]], "validation_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.validation_file"]], "validation_split_percentage (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.validation_split_percentage"]], "vision_select_layer (lmflow.args.vismodelarguments attribute)": [[5, "lmflow.args.VisModelArguments.vision_select_layer"]], "with_qformer (lmflow.args.vismodelarguments attribute)": [[5, "lmflow.args.VisModelArguments.with_qformer"]], "dataset_types (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.DATASET_TYPES"]], "dataset (class in lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.Dataset"]], "key_instances (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.KEY_INSTANCES"]], "key_type (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.KEY_TYPE"]], "__len__() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.__len__"]], "_check_data_format() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset._check_data_format"]], "create_from_dict() (lmflow.datasets.dataset.dataset class method)": [[6, "lmflow.datasets.dataset.Dataset.create_from_dict"]], "from_dict() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.from_dict"]], "get_backend() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_backend"]], "get_backend_dataset() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_backend_dataset"]], "get_data_args() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_data_args"]], "get_fingerprint() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_fingerprint"]], "get_type() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_type"]], "lmflow.datasets.dataset": [[6, "module-lmflow.datasets.dataset"]], "map() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.map"]], "to_dict() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.to_dict"]], "to_list() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.to_list"]], "custommultimodaldataset (class in lmflow.datasets)": [[7, "lmflow.datasets.CustomMultiModalDataset"]], "dataset (class in lmflow.datasets)": [[7, "lmflow.datasets.Dataset"]], "__getitem__() (lmflow.datasets.custommultimodaldataset method)": [[7, "lmflow.datasets.CustomMultiModalDataset.__getitem__"]], "__len__() (lmflow.datasets.custommultimodaldataset method)": [[7, "lmflow.datasets.CustomMultiModalDataset.__len__"]], "__len__() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.__len__"]], "_check_data_format() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset._check_data_format"]], "create_from_dict() (lmflow.datasets.dataset class method)": [[7, "lmflow.datasets.Dataset.create_from_dict"]], "from_dict() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.from_dict"]], "get_backend() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_backend"]], "get_backend_dataset() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_backend_dataset"]], "get_data_args() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_data_args"]], "get_fingerprint() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_fingerprint"]], "get_type() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_type"]], "lmflow.datasets": [[7, "module-lmflow.datasets"]], "map() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.map"]], "register_tokenizer() (lmflow.datasets.custommultimodaldataset method)": [[7, "lmflow.datasets.CustomMultiModalDataset.register_tokenizer"]], "to_dict() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.to_dict"]], "to_list() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.to_list"]], "custommultimodaldataset (class in lmflow.datasets.multi_modal_dataset)": [[8, "lmflow.datasets.multi_modal_dataset.CustomMultiModalDataset"]], "datacollatorforsuperviseddataset (class in lmflow.datasets.multi_modal_dataset)": [[8, "lmflow.datasets.multi_modal_dataset.DataCollatorForSupervisedDataset"]], "__call__() (lmflow.datasets.multi_modal_dataset.datacollatorforsuperviseddataset method)": [[8, "lmflow.datasets.multi_modal_dataset.DataCollatorForSupervisedDataset.__call__"]], "__getitem__() (lmflow.datasets.multi_modal_dataset.custommultimodaldataset method)": [[8, "lmflow.datasets.multi_modal_dataset.CustomMultiModalDataset.__getitem__"]], "__len__() (lmflow.datasets.multi_modal_dataset.custommultimodaldataset method)": [[8, "lmflow.datasets.multi_modal_dataset.CustomMultiModalDataset.__len__"]], "lmflow.datasets.multi_modal_dataset": [[8, "module-lmflow.datasets.multi_modal_dataset"]], "preprocess_llama_from_llava_plain() (in module lmflow.datasets.multi_modal_dataset)": [[8, "lmflow.datasets.multi_modal_dataset.preprocess_llama_from_llava_plain"]], "preprocess_llama_from_llava_v1() (in module lmflow.datasets.multi_modal_dataset)": [[8, "lmflow.datasets.multi_modal_dataset.preprocess_llama_from_llava_v1"]], "preprocess_multimodal_llava() (in module lmflow.datasets.multi_modal_dataset)": [[8, "lmflow.datasets.multi_modal_dataset.preprocess_multimodal_llava"]], "register_tokenizer() (lmflow.datasets.multi_modal_dataset.custommultimodaldataset method)": [[8, "lmflow.datasets.multi_modal_dataset.CustomMultiModalDataset.register_tokenizer"]], "tokenizer (lmflow.datasets.multi_modal_dataset.datacollatorforsuperviseddataset attribute)": [[8, "lmflow.datasets.multi_modal_dataset.DataCollatorForSupervisedDataset.tokenizer"]], "tokenizer_image_token() (in module lmflow.datasets.multi_modal_dataset)": [[8, "lmflow.datasets.multi_modal_dataset.tokenizer_image_token"]], "__version__ (in module lmflow)": [[9, "lmflow.__version__"]], "internal_version (in module lmflow)": [[9, "lmflow.internal_version"]], "lmflow": [[9, "module-lmflow"]], "automodel (class in lmflow.models.auto_model)": [[10, "lmflow.models.auto_model.AutoModel"]], "get_model() (lmflow.models.auto_model.automodel class method)": [[10, "lmflow.models.auto_model.AutoModel.get_model"]], "lmflow.models.auto_model": [[10, "module-lmflow.models.auto_model"]], "basemodel (class in lmflow.models.base_model)": [[11, "lmflow.models.base_model.BaseModel"]], "lmflow.models.base_model": [[11, "module-lmflow.models.base_model"]], "decodermodel (class in lmflow.models.decoder_model)": [[12, "lmflow.models.decoder_model.DecoderModel"]], "lmflow.models.decoder_model": [[12, "module-lmflow.models.decoder_model"]], "encoderdecodermodel (class in lmflow.models.encoder_decoder_model)": [[13, "lmflow.models.encoder_decoder_model.EncoderDecoderModel"]], "lmflow.models.encoder_decoder_model": [[13, "module-lmflow.models.encoder_decoder_model"]], "gpu_support_flash_attention (in module lmflow.models.hf_decoder_model)": [[14, "id0"], [14, "lmflow.models.hf_decoder_model.GPU_SUPPORT_FLASH_ATTENTION"]], "hfdecodermodel (class in lmflow.models.hf_decoder_model)": [[14, "lmflow.models.hf_decoder_model.HFDecoderModel"]], "models_support_flash_attention (in module lmflow.models.hf_decoder_model)": [[14, "lmflow.models.hf_decoder_model.MODELS_SUPPORT_FLASH_ATTENTION"]], "decode() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[14, "lmflow.models.hf_decoder_model.HFDecoderModel.decode"]], "encode() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[14, "lmflow.models.hf_decoder_model.HFDecoderModel.encode"]], "get_backend_model() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[14, "lmflow.models.hf_decoder_model.HFDecoderModel.get_backend_model"]], "get_max_length() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[14, "lmflow.models.hf_decoder_model.HFDecoderModel.get_max_length"]], "get_peft_without_qlora() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[14, "lmflow.models.hf_decoder_model.HFDecoderModel.get_peft_without_qlora"]], "get_tokenizer() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[14, "lmflow.models.hf_decoder_model.HFDecoderModel.get_tokenizer"]], "inference() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[14, "lmflow.models.hf_decoder_model.HFDecoderModel.inference"]], "lmflow.models.hf_decoder_model": [[14, "module-lmflow.models.hf_decoder_model"]], "logger (in module lmflow.models.hf_decoder_model)": [[14, "lmflow.models.hf_decoder_model.logger"]], "merge_lora_weights() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[14, "lmflow.models.hf_decoder_model.HFDecoderModel.merge_lora_weights"]], "save() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[14, "lmflow.models.hf_decoder_model.HFDecoderModel.save"]], "tokenize() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[14, "lmflow.models.hf_decoder_model.HFDecoderModel.tokenize"]], "hfencoderdecodermodel (class in lmflow.models.hf_encoder_decoder_model)": [[15, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel"]], "decode() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[15, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.decode"]], "encode() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[15, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.encode"]], "get_backend_model() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[15, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_backend_model"]], "get_max_length() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[15, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_max_length"]], "get_tokenizer() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[15, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_tokenizer"]], "inference() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[15, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.inference"]], "lmflow.models.hf_encoder_decoder_model": [[15, "module-lmflow.models.hf_encoder_decoder_model"]], "logger (in module lmflow.models.hf_encoder_decoder_model)": [[15, "lmflow.models.hf_encoder_decoder_model.logger"]], "merge_lora_weights() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[15, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.merge_lora_weights"]], "save() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[15, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.save"]], "tokenize() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[15, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.tokenize"]], "lmflow.models": [[16, "module-lmflow.models"]], "lmflow.models.interfaces": [[17, "module-lmflow.models.interfaces"]], "tunable (class in lmflow.models.interfaces.tunable)": [[18, "lmflow.models.interfaces.tunable.Tunable"]], "lmflow.models.interfaces.tunable": [[18, "module-lmflow.models.interfaces.tunable"]], "regressionmodel (class in lmflow.models.regression_model)": [[19, "lmflow.models.regression_model.RegressionModel"]], "lmflow.models.regression_model": [[19, "module-lmflow.models.regression_model"]], "textregressionmodel (class in lmflow.models.text_regression_model)": [[20, "lmflow.models.text_regression_model.TextRegressionModel"]], "inference() (lmflow.models.text_regression_model.textregressionmodel method)": [[20, "lmflow.models.text_regression_model.TextRegressionModel.inference"]], "lmflow.models.text_regression_model": [[20, "module-lmflow.models.text_regression_model"]], "register_inference_function() (lmflow.models.text_regression_model.textregressionmodel method)": [[20, "lmflow.models.text_regression_model.TextRegressionModel.register_inference_function"]], "customautovision2seqmodel (class in lmflow.models.vision2seq_model)": [[21, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel"]], "forward() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[21, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.forward"]], "generate() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[21, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.generate"]], "get_backend_model() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[21, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.get_backend_model"]], "get_tokenizer() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[21, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.get_tokenizer"]], "language_model_from_pretrained() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[21, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.language_model_from_pretrained"]], "lmflow.models.vision2seq_model": [[21, "module-lmflow.models.vision2seq_model"]], "load_prompt_cache() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[21, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.load_prompt_cache"]], "processor_image_token_in_minigpt4() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[21, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.processor_image_token_in_minigpt4"]], "qformer_from_pretrained() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[21, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.qformer_from_pretrained"]], "register_prompt_cache() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[21, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.register_prompt_cache"]], "save_prompt_cache() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[21, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.save_prompt_cache"]], "vision_feature_select() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[21, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.vision_feature_select"]], "vision_model_from_pretrained() (lmflow.models.vision2seq_model.customautovision2seqmodel method)": [[21, "lmflow.models.vision2seq_model.CustomAutoVision2SeqModel.vision_model_from_pretrained"]], "clipvisiontower (class in lmflow.models.vision_encoder.clip_encoder)": [[22, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower"]], "build_vision_tower() (in module lmflow.models.vision_encoder.clip_encoder)": [[22, "lmflow.models.vision_encoder.clip_encoder.build_vision_tower"]], "config (lmflow.models.vision_encoder.clip_encoder.clipvisiontower property)": [[22, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.config"]], "device (lmflow.models.vision_encoder.clip_encoder.clipvisiontower property)": [[22, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.device"]], "dtype (lmflow.models.vision_encoder.clip_encoder.clipvisiontower property)": [[22, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.dtype"]], "dummy_feature (lmflow.models.vision_encoder.clip_encoder.clipvisiontower property)": [[22, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.dummy_feature"]], "encode_images() (lmflow.models.vision_encoder.clip_encoder.clipvisiontower method)": [[22, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.encode_images"]], "feature_select() (lmflow.models.vision_encoder.clip_encoder.clipvisiontower method)": [[22, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.feature_select"]], "forward() (lmflow.models.vision_encoder.clip_encoder.clipvisiontower method)": [[22, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.forward"]], "hidden_size (lmflow.models.vision_encoder.clip_encoder.clipvisiontower property)": [[22, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.hidden_size"]], "lmflow.models.vision_encoder.clip_encoder": [[22, "module-lmflow.models.vision_encoder.clip_encoder"]], "load_model() (lmflow.models.vision_encoder.clip_encoder.clipvisiontower method)": [[22, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.load_model"]], "num_patches (lmflow.models.vision_encoder.clip_encoder.clipvisiontower property)": [[22, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.num_patches"]], "prepare_inputs_labels_for_multimodal() (lmflow.models.vision_encoder.clip_encoder.clipvisiontower method)": [[22, "lmflow.models.vision_encoder.clip_encoder.CLIPVisionTower.prepare_inputs_labels_for_multimodal"]], "build_vision_tower() (in module lmflow.models.vision_encoder)": [[23, "lmflow.models.vision_encoder.build_vision_tower"]], "lmflow.models.vision_encoder": [[23, "module-lmflow.models.vision_encoder"]], "autopipeline (class in lmflow.pipeline.auto_pipeline)": [[24, "lmflow.pipeline.auto_pipeline.AutoPipeline"]], "pipeline_mapping (in module lmflow.pipeline.auto_pipeline)": [[24, "lmflow.pipeline.auto_pipeline.PIPELINE_MAPPING"]], "get_pipeline() (lmflow.pipeline.auto_pipeline.autopipeline class method)": [[24, "lmflow.pipeline.auto_pipeline.AutoPipeline.get_pipeline"]], "lmflow.pipeline.auto_pipeline": [[24, "module-lmflow.pipeline.auto_pipeline"]], "basealigner (class in lmflow.pipeline.base_aligner)": [[25, "lmflow.pipeline.base_aligner.BaseAligner"]], "_check_if_alignable() (lmflow.pipeline.base_aligner.basealigner method)": [[25, "lmflow.pipeline.base_aligner.BaseAligner._check_if_alignable"]], "align() (lmflow.pipeline.base_aligner.basealigner method)": [[25, "lmflow.pipeline.base_aligner.BaseAligner.align"]], "lmflow.pipeline.base_aligner": [[25, "module-lmflow.pipeline.base_aligner"]], "basepipeline (class in lmflow.pipeline.base_pipeline)": [[26, "lmflow.pipeline.base_pipeline.BasePipeline"]], "lmflow.pipeline.base_pipeline": [[26, "module-lmflow.pipeline.base_pipeline"]], "basetuner (class in lmflow.pipeline.base_tuner)": [[27, "lmflow.pipeline.base_tuner.BaseTuner"]], "_check_if_tunable() (lmflow.pipeline.base_tuner.basetuner method)": [[27, "lmflow.pipeline.base_tuner.BaseTuner._check_if_tunable"]], "lmflow.pipeline.base_tuner": [[27, "module-lmflow.pipeline.base_tuner"]], "tune() (lmflow.pipeline.base_tuner.basetuner method)": [[27, "lmflow.pipeline.base_tuner.BaseTuner.tune"]], "evaluator (class in lmflow.pipeline.evaluator)": [[28, "lmflow.pipeline.evaluator.Evaluator"]], "_evaluate_acc_with_accelerator() (lmflow.pipeline.evaluator.evaluator method)": [[28, "lmflow.pipeline.evaluator.Evaluator._evaluate_acc_with_accelerator"]], "_evaluate_acc_with_deepspeed() (lmflow.pipeline.evaluator.evaluator method)": [[28, "lmflow.pipeline.evaluator.Evaluator._evaluate_acc_with_deepspeed"]], "_evaluate_nll() (lmflow.pipeline.evaluator.evaluator method)": [[28, "lmflow.pipeline.evaluator.Evaluator._evaluate_nll"]], "_evaluate_ppl() (lmflow.pipeline.evaluator.evaluator method)": [[28, "lmflow.pipeline.evaluator.Evaluator._evaluate_ppl"]], "_match() (lmflow.pipeline.evaluator.evaluator method)": [[28, "lmflow.pipeline.evaluator.Evaluator._match"]], "create_dataloader() (lmflow.pipeline.evaluator.evaluator method)": [[28, "lmflow.pipeline.evaluator.Evaluator.create_dataloader"]], "evaluate() (lmflow.pipeline.evaluator.evaluator method)": [[28, "lmflow.pipeline.evaluator.Evaluator.evaluate"]], "lmflow.pipeline.evaluator": [[28, "module-lmflow.pipeline.evaluator"]], "finetuner (class in lmflow.pipeline.finetuner)": [[29, "lmflow.pipeline.finetuner.Finetuner"]], "group_text() (lmflow.pipeline.finetuner.finetuner method)": [[29, "lmflow.pipeline.finetuner.Finetuner.group_text"]], "lmflow.pipeline.finetuner": [[29, "module-lmflow.pipeline.finetuner"]], "logger (in module lmflow.pipeline.finetuner)": [[29, "lmflow.pipeline.finetuner.logger"]], "tune() (lmflow.pipeline.finetuner.finetuner method)": [[29, "lmflow.pipeline.finetuner.Finetuner.tune"]], "lmflow.pipeline": [[30, "module-lmflow.pipeline"]], "inferencer (class in lmflow.pipeline.inferencer)": [[31, "lmflow.pipeline.inferencer.Inferencer"]], "speculativeinferencer (class in lmflow.pipeline.inferencer)": [[31, "lmflow.pipeline.inferencer.SpeculativeInferencer"]], "autoregressive_sampling() (lmflow.pipeline.inferencer.speculativeinferencer method)": [[31, "lmflow.pipeline.inferencer.SpeculativeInferencer.autoregressive_sampling"]], "create_dataloader() (lmflow.pipeline.inferencer.inferencer method)": [[31, "lmflow.pipeline.inferencer.Inferencer.create_dataloader"]], "inference() (lmflow.pipeline.inferencer.inferencer method)": [[31, "lmflow.pipeline.inferencer.Inferencer.inference"]], "inference() (lmflow.pipeline.inferencer.speculativeinferencer method)": [[31, "lmflow.pipeline.inferencer.SpeculativeInferencer.inference"]], "lmflow.pipeline.inferencer": [[31, "module-lmflow.pipeline.inferencer"]], "logger (in module lmflow.pipeline.inferencer)": [[31, "lmflow.pipeline.inferencer.logger"]], "predict_next_token() (lmflow.pipeline.inferencer.speculativeinferencer static method)": [[31, "lmflow.pipeline.inferencer.SpeculativeInferencer.predict_next_token"]], "rstrip_partial_utf8() (in module lmflow.pipeline.inferencer)": [[31, "lmflow.pipeline.inferencer.rstrip_partial_utf8"]], "sample() (lmflow.pipeline.inferencer.speculativeinferencer static method)": [[31, "lmflow.pipeline.inferencer.SpeculativeInferencer.sample"]], "score_to_prob() (lmflow.pipeline.inferencer.speculativeinferencer static method)": [[31, "lmflow.pipeline.inferencer.SpeculativeInferencer.score_to_prob"]], "stream_inference() (lmflow.pipeline.inferencer.inferencer method)": [[31, "lmflow.pipeline.inferencer.Inferencer.stream_inference"]], "stream_inference() (lmflow.pipeline.inferencer.speculativeinferencer method)": [[31, "lmflow.pipeline.inferencer.SpeculativeInferencer.stream_inference"]], "supported_dataset_type (in module lmflow.pipeline.inferencer)": [[31, "lmflow.pipeline.inferencer.supported_dataset_type"]], "raftaligner (class in lmflow.pipeline.raft_aligner)": [[32, "lmflow.pipeline.raft_aligner.RaftAligner"]], "_clean_text() (lmflow.pipeline.raft_aligner.raftaligner method)": [[32, "lmflow.pipeline.raft_aligner.RaftAligner._clean_text"]], "_discard_sample() (lmflow.pipeline.raft_aligner.raftaligner method)": [[32, "lmflow.pipeline.raft_aligner.RaftAligner._discard_sample"]], "_get_batch_dataset_local() (lmflow.pipeline.raft_aligner.raftaligner method)": [[32, "lmflow.pipeline.raft_aligner.RaftAligner._get_batch_dataset_local"]], "_get_batch_dataset_top() (lmflow.pipeline.raft_aligner.raftaligner method)": [[32, "lmflow.pipeline.raft_aligner.RaftAligner._get_batch_dataset_top"]], "_initialize_trainer() (lmflow.pipeline.raft_aligner.raftaligner method)": [[32, "lmflow.pipeline.raft_aligner.RaftAligner._initialize_trainer"]], "_load_dataset() (lmflow.pipeline.raft_aligner.raftaligner method)": [[32, "lmflow.pipeline.raft_aligner.RaftAligner._load_dataset"]], "_load_input_dataset() (lmflow.pipeline.raft_aligner.raftaligner method)": [[32, "lmflow.pipeline.raft_aligner.RaftAligner._load_input_dataset"]], "align() (lmflow.pipeline.raft_aligner.raftaligner method)": [[32, "lmflow.pipeline.raft_aligner.RaftAligner.align"]], "lmflow.pipeline.raft_aligner": [[32, "module-lmflow.pipeline.raft_aligner"]], "logger (in module lmflow.pipeline.raft_aligner)": [[32, "lmflow.pipeline.raft_aligner.logger"]], "lmflow.pipeline.utils": [[33, "module-lmflow.pipeline.utils"]], "peftsavingcallback (class in lmflow.pipeline.utils.peft_trainer)": [[34, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback"]], "pefttrainer (class in lmflow.pipeline.utils.peft_trainer)": [[34, "lmflow.pipeline.utils.peft_trainer.PeftTrainer"]], "_save() (lmflow.pipeline.utils.peft_trainer.peftsavingcallback method)": [[34, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback._save"]], "_save_checkpoint() (lmflow.pipeline.utils.peft_trainer.pefttrainer method)": [[34, "lmflow.pipeline.utils.peft_trainer.PeftTrainer._save_checkpoint"]], "lmflow.pipeline.utils.peft_trainer": [[34, "module-lmflow.pipeline.utils.peft_trainer"]], "on_epoch_end() (lmflow.pipeline.utils.peft_trainer.peftsavingcallback method)": [[34, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback.on_epoch_end"]], "on_save() (lmflow.pipeline.utils.peft_trainer.peftsavingcallback method)": [[34, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback.on_save"]], "on_train_end() (lmflow.pipeline.utils.peft_trainer.peftsavingcallback method)": [[34, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback.on_train_end"]], "default_callbacks (in module lmflow.pipeline.utils.raft_trainer)": [[35, "lmflow.pipeline.utils.raft_trainer.DEFAULT_CALLBACKS"]], "default_progress_callback (in module lmflow.pipeline.utils.raft_trainer)": [[35, "id0"], [35, "lmflow.pipeline.utils.raft_trainer.DEFAULT_PROGRESS_CALLBACK"]], "is_sagemaker_mp_post_1_10 (in module lmflow.pipeline.utils.raft_trainer)": [[35, "lmflow.pipeline.utils.raft_trainer.IS_SAGEMAKER_MP_POST_1_10"]], "optimizer_name (in module lmflow.pipeline.utils.raft_trainer)": [[35, "lmflow.pipeline.utils.raft_trainer.OPTIMIZER_NAME"]], "rafttrainer (class in lmflow.pipeline.utils.raft_trainer)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer"]], "scaler_name (in module lmflow.pipeline.utils.raft_trainer)": [[35, "lmflow.pipeline.utils.raft_trainer.SCALER_NAME"]], "scheduler_name (in module lmflow.pipeline.utils.raft_trainer)": [[35, "lmflow.pipeline.utils.raft_trainer.SCHEDULER_NAME"]], "trainer_state_name (in module lmflow.pipeline.utils.raft_trainer)": [[35, "lmflow.pipeline.utils.raft_trainer.TRAINER_STATE_NAME"]], "training_args_name (in module lmflow.pipeline.utils.raft_trainer)": [[35, "lmflow.pipeline.utils.raft_trainer.TRAINING_ARGS_NAME"]], "_add_sm_patterns_to_gitignore() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._add_sm_patterns_to_gitignore"]], "_gather_and_numpify() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._gather_and_numpify"]], "_get_collator_with_removed_columns() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_collator_with_removed_columns"]], "_get_eval_sampler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_eval_sampler"]], "_get_output_dir() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_output_dir"]], "_get_train_sampler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_train_sampler"]], "_hp_search_setup() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._hp_search_setup"]], "_inner_training_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._inner_training_loop"]], "_is_native_cpu_amp_available (in module lmflow.pipeline.utils.raft_trainer)": [[35, "lmflow.pipeline.utils.raft_trainer._is_native_cpu_amp_available"]], "_issue_warnings_after_load() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._issue_warnings_after_load"]], "_load_best_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_best_model"]], "_load_from_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_from_checkpoint"]], "_load_optimizer_and_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_optimizer_and_scheduler"]], "_load_rng_state() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_rng_state"]], "_maybe_log_save_evaluate() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._maybe_log_save_evaluate"]], "_move_model_to_device() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._move_model_to_device"]], "_nested_gather() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._nested_gather"]], "_one_train() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._one_train"]], "_pad_across_processes() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._pad_across_processes"]], "_prepare_input() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._prepare_input"]], "_prepare_inputs() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._prepare_inputs"]], "_push_from_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._push_from_checkpoint"]], "_remove_unused_columns() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._remove_unused_columns"]], "_report_to_hp_search() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._report_to_hp_search"]], "_rotate_checkpoints() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._rotate_checkpoints"]], "_save() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save"]], "_save_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save_checkpoint"]], "_save_tpu() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save_tpu"]], "_set_signature_columns_if_needed() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._set_signature_columns_if_needed"]], "_sorted_checkpoints() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._sorted_checkpoints"]], "_tune_save_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._tune_save_checkpoint"]], "_wrap_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._wrap_model"]], "add_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.add_callback"]], "autocast_smart_context_manager() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.autocast_smart_context_manager"]], "call_model_init() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.call_model_init"]], "compute_loss() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.compute_loss"]], "compute_loss_context_manager() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.compute_loss_context_manager"]], "create_model_card() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_model_card"]], "create_optimizer() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_optimizer"]], "create_optimizer_and_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_optimizer_and_scheduler"]], "create_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_scheduler"]], "evaluate() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.evaluate"]], "evaluation_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.evaluation_loop"]], "floating_point_ops() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.floating_point_ops"]], "get_eval_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_eval_dataloader"]], "get_optimizer_cls_and_kwargs() (lmflow.pipeline.utils.raft_trainer.rafttrainer static method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_optimizer_cls_and_kwargs"]], "get_test_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_test_dataloader"]], "get_train_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_train_dataloader"]], "hyperparameter_search() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.hyperparameter_search"]], "init_git_repo() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.init_git_repo"]], "ipex_optimize_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.ipex_optimize_model"]], "is_local_process_zero() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.is_local_process_zero"]], "is_torch_greater_or_equal_than_1_10 (in module lmflow.pipeline.utils.raft_trainer)": [[35, "lmflow.pipeline.utils.raft_trainer.is_torch_greater_or_equal_than_1_10"]], "is_torch_less_than_1_11 (in module lmflow.pipeline.utils.raft_trainer)": [[35, "lmflow.pipeline.utils.raft_trainer.is_torch_less_than_1_11"]], "is_world_process_zero() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.is_world_process_zero"]], "lmflow.pipeline.utils.raft_trainer": [[35, "module-lmflow.pipeline.utils.raft_trainer"]], "log() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.log"]], "logger (in module lmflow.pipeline.utils.raft_trainer)": [[35, "lmflow.pipeline.utils.raft_trainer.logger"]], "num_examples() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.num_examples"]], "pop_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.pop_callback"]], "predict() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.predict"]], "prediction_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.prediction_loop"]], "prediction_step() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.prediction_step"]], "push_to_hub() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.push_to_hub"]], "remove_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.remove_callback"]], "save_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.save_model"]], "skip_first_batches (in module lmflow.pipeline.utils.raft_trainer)": [[35, "lmflow.pipeline.utils.raft_trainer.skip_first_batches"]], "store_flos() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.store_flos"]], "torch_jit_model_eval() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.torch_jit_model_eval"]], "train() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.train"]], "training_step() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[35, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.training_step"]], "controller_heart_beat_expiration (in module lmflow.utils.constants)": [[36, "lmflow.utils.constants.CONTROLLER_HEART_BEAT_EXPIRATION"]], "dataset_description_map (in module lmflow.utils.constants)": [[36, "lmflow.utils.constants.DATASET_DESCRIPTION_MAP"]], "default_image_patch_token (in module lmflow.utils.constants)": [[36, "lmflow.utils.constants.DEFAULT_IMAGE_PATCH_TOKEN"]], "default_image_token (in module lmflow.utils.constants)": [[36, "lmflow.utils.constants.DEFAULT_IMAGE_TOKEN"]], "default_im_end_token (in module lmflow.utils.constants)": [[36, "lmflow.utils.constants.DEFAULT_IM_END_TOKEN"]], "default_im_start_token (in module lmflow.utils.constants)": [[36, "lmflow.utils.constants.DEFAULT_IM_START_TOKEN"]], "float_only_dataset_description (in module lmflow.utils.constants)": [[36, "lmflow.utils.constants.FLOAT_ONLY_DATASET_DESCRIPTION"]], "ignore_index (in module lmflow.utils.constants)": [[36, "lmflow.utils.constants.IGNORE_INDEX"]], "image_token_index (in module lmflow.utils.constants)": [[36, "lmflow.utils.constants.IMAGE_TOKEN_INDEX"]], "instance_fields_map (in module lmflow.utils.constants)": [[36, "lmflow.utils.constants.INSTANCE_FIELDS_MAP"]], "logdir (in module lmflow.utils.constants)": [[36, "lmflow.utils.constants.LOGDIR"]], "text2text_dataset_description (in module lmflow.utils.constants)": [[36, "lmflow.utils.constants.TEXT2TEXT_DATASET_DESCRIPTION"]], "text2text_dataset_details (in module lmflow.utils.constants)": [[36, "lmflow.utils.constants.TEXT2TEXT_DATASET_DETAILS"]], "text2text_dataset_long_descrition (in module lmflow.utils.constants)": [[36, "lmflow.utils.constants.TEXT2TEXT_DATASET_LONG_DESCRITION"]], "text_only_dataset_description (in module lmflow.utils.constants)": [[36, "lmflow.utils.constants.TEXT_ONLY_DATASET_DESCRIPTION"]], "text_only_dataset_details (in module lmflow.utils.constants)": [[36, "lmflow.utils.constants.TEXT_ONLY_DATASET_DETAILS"]], "text_only_dataset_long_descrition (in module lmflow.utils.constants)": [[36, "lmflow.utils.constants.TEXT_ONLY_DATASET_LONG_DESCRITION"]], "worker_heart_beat_interval (in module lmflow.utils.constants)": [[36, "lmflow.utils.constants.WORKER_HEART_BEAT_INTERVAL"]], "lmflow.utils.constants": [[36, "module-lmflow.utils.constants"]], "answer_extraction() (in module lmflow.utils.data_utils)": [[37, "lmflow.utils.data_utils.answer_extraction"]], "batchlize() (in module lmflow.utils.data_utils)": [[37, "lmflow.utils.data_utils.batchlize"]], "lmflow.utils.data_utils": [[37, "module-lmflow.utils.data_utils"]], "load_data() (in module lmflow.utils.data_utils)": [[37, "lmflow.utils.data_utils.load_data"]], "process_image_flag() (in module lmflow.utils.data_utils)": [[37, "lmflow.utils.data_utils.process_image_flag"]], "set_random_seed() (in module lmflow.utils.data_utils)": [[37, "lmflow.utils.data_utils.set_random_seed"]], "_prepare_attn_mask() (in module lmflow.utils.flash_attention.bloom_flash_attention)": [[38, "lmflow.utils.flash_attention.bloom_flash_attention._prepare_attn_mask"]], "forward() (in module lmflow.utils.flash_attention.bloom_flash_attention)": [[38, "lmflow.utils.flash_attention.bloom_flash_attention.forward"]], "lmflow.utils.flash_attention.bloom_flash_attention": [[38, "module-lmflow.utils.flash_attention.bloom_flash_attention"]], "replace_bloom_attn_with_flash_attn() (in module lmflow.utils.flash_attention.bloom_flash_attention)": [[38, "lmflow.utils.flash_attention.bloom_flash_attention.replace_bloom_attn_with_flash_attn"]], "_prepare_decoder_attention_mask() (in module lmflow.utils.flash_attention.gpt2_flash_attention)": [[39, "lmflow.utils.flash_attention.gpt2_flash_attention._prepare_decoder_attention_mask"]], "forward() (in module lmflow.utils.flash_attention.gpt2_flash_attention)": [[39, "lmflow.utils.flash_attention.gpt2_flash_attention.forward"]], "lmflow.utils.flash_attention.gpt2_flash_attention": [[39, "module-lmflow.utils.flash_attention.gpt2_flash_attention"]], "replace_gpt2_attn_with_flash_attn() (in module lmflow.utils.flash_attention.gpt2_flash_attention)": [[39, "lmflow.utils.flash_attention.gpt2_flash_attention.replace_gpt2_attn_with_flash_attn"]], "_attn() (in module lmflow.utils.flash_attention.gpt_neo_flash_attention)": [[40, "lmflow.utils.flash_attention.gpt_neo_flash_attention._attn"]], "forward() (in module lmflow.utils.flash_attention.gpt_neo_flash_attention)": [[40, "lmflow.utils.flash_attention.gpt_neo_flash_attention.forward"]], "lmflow.utils.flash_attention.gpt_neo_flash_attention": [[40, "module-lmflow.utils.flash_attention.gpt_neo_flash_attention"]], "replace_gpt_neo_attn_with_flash_attn() (in module lmflow.utils.flash_attention.gpt_neo_flash_attention)": [[40, "lmflow.utils.flash_attention.gpt_neo_flash_attention.replace_gpt_neo_attn_with_flash_attn"]], "lmflow.utils.flash_attention": [[41, "module-lmflow.utils.flash_attention"]], "_prepare_decoder_attention_mask() (in module lmflow.utils.flash_attention.llama_flash_attention)": [[42, "lmflow.utils.flash_attention.llama_flash_attention._prepare_decoder_attention_mask"]], "forward() (in module lmflow.utils.flash_attention.llama_flash_attention)": [[42, "lmflow.utils.flash_attention.llama_flash_attention.forward"]], "lmflow.utils.flash_attention.llama_flash_attention": [[42, "module-lmflow.utils.flash_attention.llama_flash_attention"]], "replace_llama_attn_with_flash_attn() (in module lmflow.utils.flash_attention.llama_flash_attention)": [[42, "lmflow.utils.flash_attention.llama_flash_attention.replace_llama_attn_with_flash_attn"]], "flashattnfunc (class in lmflow.utils.flash_attention.triton_flash_attention)": [[43, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnFunc"]], "flashattnkvpackedfunc (class in lmflow.utils.flash_attention.triton_flash_attention)": [[43, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnKVPackedFunc"]], "flashattnqkvpackedfunc (class in lmflow.utils.flash_attention.triton_flash_attention)": [[43, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnQKVPackedFunc"]], "_bwd_kernel() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[43, "lmflow.utils.flash_attention.triton_flash_attention._bwd_kernel"]], "_bwd_kernel_one_col_block() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[43, "lmflow.utils.flash_attention.triton_flash_attention._bwd_kernel_one_col_block"]], "_bwd_preprocess_do_o_dot() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[43, "lmflow.utils.flash_attention.triton_flash_attention._bwd_preprocess_do_o_dot"]], "_bwd_store_dk_dv() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[43, "lmflow.utils.flash_attention.triton_flash_attention._bwd_store_dk_dv"]], "_flash_attn_backward() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[43, "lmflow.utils.flash_attention.triton_flash_attention._flash_attn_backward"]], "_flash_attn_forward() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[43, "lmflow.utils.flash_attention.triton_flash_attention._flash_attn_forward"]], "_fwd_kernel() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[43, "lmflow.utils.flash_attention.triton_flash_attention._fwd_kernel"]], "backward() (lmflow.utils.flash_attention.triton_flash_attention.flashattnfunc static method)": [[43, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnFunc.backward"]], "backward() (lmflow.utils.flash_attention.triton_flash_attention.flashattnkvpackedfunc static method)": [[43, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnKVPackedFunc.backward"]], "backward() (lmflow.utils.flash_attention.triton_flash_attention.flashattnqkvpackedfunc static method)": [[43, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnQKVPackedFunc.backward"]], "flash_attn_func (in module lmflow.utils.flash_attention.triton_flash_attention)": [[43, "lmflow.utils.flash_attention.triton_flash_attention.flash_attn_func"]], "flash_attn_kvpacked_func (in module lmflow.utils.flash_attention.triton_flash_attention)": [[43, "lmflow.utils.flash_attention.triton_flash_attention.flash_attn_kvpacked_func"]], "flash_attn_qkvpacked_func (in module lmflow.utils.flash_attention.triton_flash_attention)": [[43, "lmflow.utils.flash_attention.triton_flash_attention.flash_attn_qkvpacked_func"]], "forward() (lmflow.utils.flash_attention.triton_flash_attention.flashattnfunc static method)": [[43, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnFunc.forward"]], "forward() (lmflow.utils.flash_attention.triton_flash_attention.flashattnkvpackedfunc static method)": [[43, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnKVPackedFunc.forward"]], "forward() (lmflow.utils.flash_attention.triton_flash_attention.flashattnqkvpackedfunc static method)": [[43, "lmflow.utils.flash_attention.triton_flash_attention.FlashAttnQKVPackedFunc.forward"]], "init_to_zero() (in module lmflow.utils.flash_attention.triton_flash_attention)": [[43, "lmflow.utils.flash_attention.triton_flash_attention.init_to_zero"]], "lmflow.utils.flash_attention.triton_flash_attention": [[43, "module-lmflow.utils.flash_attention.triton_flash_attention"]], "lmflow.utils": [[44, "module-lmflow.utils"]], "conversation (class in lmflow.utils.llava_conversation_lib)": [[45, "lmflow.utils.llava_conversation_lib.Conversation"]], "llama_2 (lmflow.utils.llava_conversation_lib.separatorstyle attribute)": [[45, "lmflow.utils.llava_conversation_lib.SeparatorStyle.LLAMA_2"]], "mpt (lmflow.utils.llava_conversation_lib.separatorstyle attribute)": [[45, "lmflow.utils.llava_conversation_lib.SeparatorStyle.MPT"]], "plain (lmflow.utils.llava_conversation_lib.separatorstyle attribute)": [[45, "lmflow.utils.llava_conversation_lib.SeparatorStyle.PLAIN"]], "single (lmflow.utils.llava_conversation_lib.separatorstyle attribute)": [[45, "lmflow.utils.llava_conversation_lib.SeparatorStyle.SINGLE"]], "separatorstyle (class in lmflow.utils.llava_conversation_lib)": [[45, "lmflow.utils.llava_conversation_lib.SeparatorStyle"]], "two (lmflow.utils.llava_conversation_lib.separatorstyle attribute)": [[45, "lmflow.utils.llava_conversation_lib.SeparatorStyle.TWO"]], "append_message() (lmflow.utils.llava_conversation_lib.conversation method)": [[45, "lmflow.utils.llava_conversation_lib.Conversation.append_message"]], "conv_llama_2 (in module lmflow.utils.llava_conversation_lib)": [[45, "lmflow.utils.llava_conversation_lib.conv_llama_2"]], "conv_llava_llama_2 (in module lmflow.utils.llava_conversation_lib)": [[45, "lmflow.utils.llava_conversation_lib.conv_llava_llama_2"]], "conv_llava_plain (in module lmflow.utils.llava_conversation_lib)": [[45, "lmflow.utils.llava_conversation_lib.conv_llava_plain"]], "conv_llava_v0 (in module lmflow.utils.llava_conversation_lib)": [[45, "lmflow.utils.llava_conversation_lib.conv_llava_v0"]], "conv_llava_v0_mmtag (in module lmflow.utils.llava_conversation_lib)": [[45, "lmflow.utils.llava_conversation_lib.conv_llava_v0_mmtag"]], "conv_llava_v1 (in module lmflow.utils.llava_conversation_lib)": [[45, "lmflow.utils.llava_conversation_lib.conv_llava_v1"]], "conv_llava_v1_mmtag (in module lmflow.utils.llava_conversation_lib)": [[45, "lmflow.utils.llava_conversation_lib.conv_llava_v1_mmtag"]], "conv_mpt (in module lmflow.utils.llava_conversation_lib)": [[45, "lmflow.utils.llava_conversation_lib.conv_mpt"]], "conv_templates (in module lmflow.utils.llava_conversation_lib)": [[45, "lmflow.utils.llava_conversation_lib.conv_templates"]], "conv_vicuna_v0 (in module lmflow.utils.llava_conversation_lib)": [[45, "lmflow.utils.llava_conversation_lib.conv_vicuna_v0"]], "conv_vicuna_v1 (in module lmflow.utils.llava_conversation_lib)": [[45, "lmflow.utils.llava_conversation_lib.conv_vicuna_v1"]], "copy() (lmflow.utils.llava_conversation_lib.conversation method)": [[45, "lmflow.utils.llava_conversation_lib.Conversation.copy"]], "default_conversation (in module lmflow.utils.llava_conversation_lib)": [[45, "lmflow.utils.llava_conversation_lib.default_conversation"]], "dict() (lmflow.utils.llava_conversation_lib.conversation method)": [[45, "lmflow.utils.llava_conversation_lib.Conversation.dict"]], "get_images() (lmflow.utils.llava_conversation_lib.conversation method)": [[45, "lmflow.utils.llava_conversation_lib.Conversation.get_images"]], "get_prompt() (lmflow.utils.llava_conversation_lib.conversation method)": [[45, "lmflow.utils.llava_conversation_lib.Conversation.get_prompt"]], "lmflow.utils.llava_conversation_lib": [[45, "module-lmflow.utils.llava_conversation_lib"]], "messages (lmflow.utils.llava_conversation_lib.conversation attribute)": [[45, "lmflow.utils.llava_conversation_lib.Conversation.messages"]], "offset (lmflow.utils.llava_conversation_lib.conversation attribute)": [[45, "lmflow.utils.llava_conversation_lib.Conversation.offset"]], "roles (lmflow.utils.llava_conversation_lib.conversation attribute)": [[45, "lmflow.utils.llava_conversation_lib.Conversation.roles"]], "sep (lmflow.utils.llava_conversation_lib.conversation attribute)": [[45, "lmflow.utils.llava_conversation_lib.Conversation.sep"]], "sep2 (lmflow.utils.llava_conversation_lib.conversation attribute)": [[45, "lmflow.utils.llava_conversation_lib.Conversation.sep2"]], "sep_style (lmflow.utils.llava_conversation_lib.conversation attribute)": [[45, "lmflow.utils.llava_conversation_lib.Conversation.sep_style"]], "skip_next (lmflow.utils.llava_conversation_lib.conversation attribute)": [[45, "lmflow.utils.llava_conversation_lib.Conversation.skip_next"]], "system (lmflow.utils.llava_conversation_lib.conversation attribute)": [[45, "lmflow.utils.llava_conversation_lib.Conversation.system"]], "to_gradio_chatbot() (lmflow.utils.llava_conversation_lib.conversation method)": [[45, "lmflow.utils.llava_conversation_lib.Conversation.to_gradio_chatbot"]], "version (lmflow.utils.llava_conversation_lib.conversation attribute)": [[45, "lmflow.utils.llava_conversation_lib.Conversation.version"]], "adapt_llava_model_to_lmflow_type() (in module lmflow.utils.multimodal)": [[46, "lmflow.utils.multimodal.adapt_llava_model_to_lmflow_type"]], "lmflow.utils.multimodal": [[46, "module-lmflow.utils.multimodal"]], "load_llava_pretrain_model() (in module lmflow.utils.multimodal)": [[46, "lmflow.utils.multimodal.load_llava_pretrain_model"]], "update_custom_config() (in module lmflow.utils.multimodal)": [[46, "lmflow.utils.multimodal.update_custom_config"]], "lmflow.utils.position_interpolation": [[47, "module-lmflow.utils.position_interpolation"]], "condenserotaryembedding (class in lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch)": [[48, "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.CondenseRotaryEmbedding"]], "forward() (lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.condenserotaryembedding method)": [[48, "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.CondenseRotaryEmbedding.forward"]], "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch": [[48, "module-lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch"]], "replace_llama_with_condense() (in module lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch)": [[48, "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch.replace_llama_with_condense"]], "__version__ (in module lmflow.version)": [[49, "lmflow.version.__version__"]], "lmflow.version": [[49, "module-lmflow.version"]]}})